{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Chargingevent', 'CPID', 'Connector', 'StartDate', 'StartTime',\n",
       "       'EndDate', 'EndTime', 'StartDate_num', 'StartTime_num', 'EndDate_num',\n",
       "       'EndTime_num', 'duration', 'TotalkWh', 'Cost', 'Site', 'Group', 'Model',\n",
       "       'Model1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data_chg_all.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 15901\n",
      "Number of days: 92\n"
     ]
    }
   ],
   "source": [
    "# Convert 'StartDate' to datetime with the correct format\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'], format='%m/%d/%Y')\n",
    "\n",
    "# Define the date range\n",
    "start_date = pd.Timestamp('2018-03-05')\n",
    "end_date = pd.Timestamp('2018-06-04')\n",
    "\n",
    "# Filter the dataset to include only rows within the date range\n",
    "df = df[(df['StartDate'] >= start_date) & (df['StartDate'] <= end_date)]\n",
    "\n",
    "print('Number of rows in dataset:', len(df))\n",
    "\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "print('Number of days:', len(all_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charger Counts:\n",
      "Model1\n",
      "Slow     40\n",
      "fast      8\n",
      "rapid     9\n",
      "Name: CPID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grouped_counts = df.groupby(['Model1'])\n",
    "\n",
    "print(\"Charger Counts:\")\n",
    "print(grouped_counts['CPID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charger Percentages:\n",
      "rapid    56.229168\n",
      "Slow     35.236778\n",
      "fast      8.534054\n",
      "Name: Model1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each type of charger\n",
    "charger_counts = df['Model1'].value_counts()\n",
    "\n",
    "# Calculate the total number of charging sessions\n",
    "total_sessions = len(df)\n",
    "\n",
    "# Calculate the percentage of sessions for each type of charger\n",
    "charger_percentages = (charger_counts / total_sessions) * 100\n",
    "\n",
    "print(\"Charger Percentages:\")\n",
    "print(charger_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79% of outliers were removed.\n"
     ]
    }
   ],
   "source": [
    "# Keep only the rapid chargers\n",
    "rapid_chargers_df = df[df['Model1'] == 'rapid']\n",
    "\n",
    "# Calculate the median and standard deviation of the 'duration' column for rapid chargers\n",
    "median_duration = rapid_chargers_df['duration'].median()\n",
    "std_duration = rapid_chargers_df['duration'].std()\n",
    "\n",
    "# Define the threshold for outliers\n",
    "upper_threshold = median_duration + 3 * std_duration\n",
    "lower_threshold = median_duration - 3 * std_duration\n",
    "\n",
    "# Filter out the outliers\n",
    "filtered_df = rapid_chargers_df[(rapid_chargers_df['duration'] >= lower_threshold) & (rapid_chargers_df['duration'] <= upper_threshold )]\n",
    "\n",
    "# Check the percentage of rows removed\n",
    "percent_removed = (1 - len(filtered_df) / len(rapid_chargers_df)) * 100\n",
    "print(f'{percent_removed:.2f}% of outliers were removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8941.000000\n",
       "mean       28.313723\n",
       "std        36.412521\n",
       "min         5.000000\n",
       "25%        15.000000\n",
       "50%        24.000000\n",
       "75%        34.000000\n",
       "max      1145.000000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapid_chargers_df['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8870.000000\n",
       "mean       25.860203\n",
       "std        14.171344\n",
       "min         5.000000\n",
       "25%        15.000000\n",
       "50%        24.000000\n",
       "75%        33.000000\n",
       "max       127.000000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create dataset for hybrid lstm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'StartDate' and 'EndDate' to datetime to get the day of the week\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'])\n",
    "df['EndDate'] = pd.to_datetime(df['EndDate'])\n",
    "\n",
    "# Extract the name of the day\n",
    "df['NameOfDay'] =  df['StartDate'].dt.day_name()\n",
    "\n",
    "# Adjust DayOfWeek to start with Sunday=0, Monday=1, ..., Saturday=6\n",
    "df['DayOfWeek'] = (df['StartDate'].dt.dayofweek + 1) % 7\n",
    "\n",
    "# Determine if it is a weekend\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x in [0, 6] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[50692, 50339, 50911, 50349, 50338, 51547, 51550, 51549, 51548]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['CPID'].nunique())\n",
    "df['CPID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "771\n",
      "897\n",
      "1389\n",
      "1669\n",
      "1113\n",
      "1322\n",
      "891\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "# Group by CPID\n",
    "grouped = df.groupby('CPID')\n",
    "columns = ['StartDate', 'StartTime', 'EndDate', 'EndTime', 'StartDate_num', 'StartTime_num', 'EndDate_num', 'EndTime_num', 'NameOfDay', 'DayOfWeek', 'IsWeekend']\n",
    "\n",
    "# Create a dictionary where keys are CPID and values are DataFrames of each CPID\n",
    "cpid_dict = {cpid: group.drop(columns='CPID') for cpid, group in grouped}\n",
    "\n",
    "# Assuming cpid_dict is already defined\n",
    "for idx, (cpid, df) in enumerate(cpid_dict.items(), start=1):\n",
    "    globals()[f'df_{idx}'] = df[columns]\n",
    "    #globals()[f'df_{idx}'] = df\n",
    "    print(len(globals()[f'df_{idx}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_charging_data(df_transactions):\n",
    "    # Ensure columns are in string format\n",
    "    df_transactions['StartDate'] = df_transactions['StartDate'].astype(str)\n",
    "    df_transactions['StartTime'] = df_transactions['StartTime'].astype(str)\n",
    "    df_transactions['EndDate'] = df_transactions['EndDate'].astype(str)\n",
    "    df_transactions['EndTime'] = df_transactions['EndTime'].astype(str)\n",
    "\n",
    "    # Combine StartDate and StartTime into a single datetime column\n",
    "    df_transactions['StartDate_and_StartTime'] = pd.to_datetime(df_transactions['StartDate'] + ' ' + df_transactions['StartTime'])\n",
    "    df_transactions['EndDate_and_EndTime'] = pd.to_datetime(df_transactions['EndDate'] + ' ' + df_transactions['EndTime'])\n",
    "\n",
    "    # Extract unique dates\n",
    "    unique_dates = df_transactions[['StartDate']].drop_duplicates()\n",
    "\n",
    "    # Function to generate 10-minute intervals for a given date\n",
    "    def generate_intervals(date):\n",
    "        start_time = pd.Timestamp(date)\n",
    "        intervals_start = pd.date_range(start=start_time, periods=144, freq='10T')\n",
    "        intervals_end = intervals_start + pd.Timedelta(minutes=10)\n",
    "        return intervals_start, intervals_end\n",
    "\n",
    "    # Generate the intervals for all unique dates and create the DataFrame\n",
    "    intervals_list = []\n",
    "\n",
    "    for idx, row in unique_dates.iterrows():\n",
    "        date = row['StartDate']\n",
    "        intervals_start, intervals_end = generate_intervals(date)\n",
    "        data_chg = pd.DataFrame({\n",
    "            'StartDate': date,\n",
    "            'IntervalStart': intervals_start,\n",
    "            'IntervalEnd': intervals_end,\n",
    "            't': np.arange(1, 145)\n",
    "        })\n",
    "        intervals_list.append(data_chg)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into one\n",
    "    data_chg = pd.concat(intervals_list).reset_index(drop=True)\n",
    "\n",
    "    # Add transaction indicator\n",
    "    def add_transaction_y_indicator(intervals_df, transactions_df):\n",
    "        y_values = []\n",
    "\n",
    "        for idx, row in intervals_df.iterrows():\n",
    "            interval_start = row['IntervalStart']\n",
    "            interval_end = row['IntervalEnd']\n",
    "            \n",
    "            # Check if any transaction falls within the interval\n",
    "            transaction_exists = transactions_df[\n",
    "                (transactions_df['StartDate_and_StartTime'] < interval_end) & \n",
    "                (transactions_df['EndDate_and_EndTime'] > interval_start)\n",
    "            ].shape[0] > 0\n",
    "            \n",
    "            y_values.append(1 if transaction_exists else 0)\n",
    "        \n",
    "        intervals_df['y'] = y_values\n",
    "        return intervals_df\n",
    "    \n",
    "    def past_chg_occ_state(data_chg, df_transactions):\n",
    "        data_chg = add_transaction_y_indicator(data_chg, df_transactions)\n",
    "    \n",
    "        # Add the y_t_1 column\n",
    "        data_chg['y_t_1'] = data_chg['y'].shift(1).astype('Int64')\n",
    "\n",
    "        return data_chg\n",
    "\n",
    "    def add_weekdays_and_weekends(data_chg, df_transactions):\n",
    "        data_chg = past_chg_occ_state(data_chg, df_transactions)\n",
    "\n",
    "        # Convert 'StartDate' and 'EndDate' to datetime to get the day of the week\n",
    "        data_chg['StartDate'] = pd.to_datetime(data_chg['StartDate'])\n",
    "        # Extract the name of the day\n",
    "        data_chg['NameOfDay'] =  data_chg['StartDate'].dt.day_name()\n",
    "        # Adjust DayOfWeek to start with Sunday=0, Monday=1, ..., Saturday=6\n",
    "        data_chg['dayofweek'] = (data_chg['StartDate'].dt.dayofweek + 1) % 7\n",
    "        # Determine if it is a weekend\n",
    "        data_chg['weekend'] = data_chg['dayofweek'].apply(lambda x: 1 if x in [0, 6] else 0)\n",
    "\n",
    "        return data_chg\n",
    "\n",
    "    data_chg = add_weekdays_and_weekends(data_chg, df_transactions).dropna()[:-144]\n",
    "\n",
    "    print(len(data_chg) + 1)\n",
    "    return data_chg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784\n",
      "13104\n",
      "12672\n",
      "12816\n",
      "13104\n",
      "8496\n",
      "8496\n",
      "8496\n",
      "8496\n"
     ]
    }
   ],
   "source": [
    "data_chg_1 = process_charging_data(df_1)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_2 = process_charging_data(df_2)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_3 = process_charging_data(df_3)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_4 = process_charging_data(df_4)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_5 = process_charging_data(df_5)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_6 = process_charging_data(df_6)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_7 = process_charging_data(df_7)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_8 = process_charging_data(df_8)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "data_chg_9 = process_charging_data(df_9)[['t','StartDate', 'NameOfDay', 'dayofweek', 'weekend', 'y_t_1', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>y_t_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8783 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        t  dayofweek  weekend  y_t_1  y\n",
       "1       2          1        0      0  0\n",
       "2       3          1        0      0  0\n",
       "3       4          1        0      0  0\n",
       "4       5          1        0      0  0\n",
       "5       6          1        0      0  0\n",
       "...   ...        ...      ...    ... ..\n",
       "8779  140          5        0      0  0\n",
       "8780  141          5        0      0  0\n",
       "8781  142          5        0      0  0\n",
       "8782  143          5        0      0  0\n",
       "8783  144          5        0      0  0\n",
       "\n",
       "[8783 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chg_1[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_1 = pd.read_csv('data/data_chg/data_chg_1.csv')\n",
    "chg_2 = pd.read_csv('data/data_chg/data_chg_2.csv')\n",
    "chg_2.rename(columns={'y.1': 'y_t_1'}, inplace=True)\n",
    "chg_2 = chg_2[['t','dayofweek', 'weekend', 'y_t_1', 'y']]\n",
    "chg_3 = pd.read_csv('data/data_chg/data_chg_3.csv')\n",
    "chg_4 = pd.read_csv('data/data_chg/data_chg_4.csv')\n",
    "chg_5 = pd.read_csv('data/data_chg/data_chg_5.csv')\n",
    "chg_6 = pd.read_csv('data/data_chg/data_chg_6.csv')\n",
    "chg_7 = pd.read_csv('data/data_chg/data_chg_7.csv')\n",
    "chg_8 = pd.read_csv('data/data_chg/data_chg_8.csv')\n",
    "chg_9 = pd.read_csv('data/data_chg/data_chg_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diff rows is: 8\n",
      "Number of diff rows is: 1281\n",
      "Number of diff rows is: 162\n",
      "Number of diff rows is: 181\n",
      "Number of diff rows is: 235\n",
      "Number of diff rows is: 146\n",
      "Number of diff rows is: 213\n",
      "Number of diff rows is: 137\n",
      "Number of diff rows is: 102\n"
     ]
    }
   ],
   "source": [
    "def reset_index_and_compare_dfs(df1, df2):\n",
    "    # Reset index for both DataFrames\n",
    "    df1_reset = df1.reset_index(drop=True)\n",
    "    df2_reset = df2.reset_index(drop=True)\n",
    "\n",
    "    # Perform the comparison\n",
    "    comparison = df1_reset != df2_reset\n",
    "\n",
    "    # Identify rows with at least one differing value\n",
    "    rows_with_differences = comparison.any(axis=1)\n",
    "\n",
    "    # Get the rows from df1 and df2 where differences exist\n",
    "    df1_differing_rows = df1_reset[rows_with_differences]\n",
    "    df2_differing_rows = df2_reset[rows_with_differences]\n",
    "\n",
    "    print('Number of diff rows is:', len(df1_differing_rows))\n",
    "    \n",
    "    #return df1_differing_rows, df2_differing_rows\n",
    "\n",
    "\n",
    "reset_index_and_compare_dfs(data_chg_1[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_1)\n",
    "reset_index_and_compare_dfs(data_chg_2[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_2)\n",
    "reset_index_and_compare_dfs(data_chg_3[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_3)\n",
    "reset_index_and_compare_dfs(data_chg_4[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_4)\n",
    "reset_index_and_compare_dfs(data_chg_5[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_5)\n",
    "reset_index_and_compare_dfs(data_chg_6[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_6)\n",
    "reset_index_and_compare_dfs(data_chg_7[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_7)\n",
    "reset_index_and_compare_dfs(data_chg_8[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_8)\n",
    "reset_index_and_compare_dfs(data_chg_9[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], chg_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occupancy_rate(df):\n",
    "    # Filter DataFrame\n",
    "    weekends = df[df['NameOfDay'].isin(['Saturday', 'Sunday'])]\n",
    "    weekdays = df[~df['NameOfDay'].isin(['Saturday', 'Sunday'])]\n",
    "\n",
    "    # Pivot and calculate mean for weekdays\n",
    "    mean_y_weekday = weekdays.pivot(index='StartDate', columns='t', values='y').fillna(0).mean()\n",
    "\n",
    "    # Pivot and calculate mean for weekends\n",
    "    mean_y_weekend = weekends.pivot(index='StartDate', columns='t', values='y').fillna(0).mean()\n",
    "\n",
    "    # Combine the mean values into a DataFrame\n",
    "    data_chg_pred_occ_t = pd.DataFrame({\n",
    "        'weekday': mean_y_weekday,\n",
    "        'weekend': mean_y_weekend\n",
    "    }).reset_index()\n",
    "\n",
    "    return data_chg_pred_occ_t.drop(columns='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chg_pred_occ_t_1 = calculate_occupancy_rate(data_chg_1)\n",
    "data_chg_pred_occ_t_2 = calculate_occupancy_rate(data_chg_2)\n",
    "data_chg_pred_occ_t_3 = calculate_occupancy_rate(data_chg_3)\n",
    "data_chg_pred_occ_t_4 = calculate_occupancy_rate(data_chg_4)\n",
    "data_chg_pred_occ_t_5 = calculate_occupancy_rate(data_chg_5)\n",
    "data_chg_pred_occ_t_6 = calculate_occupancy_rate(data_chg_6)\n",
    "data_chg_pred_occ_t_7 = calculate_occupancy_rate(data_chg_7)\n",
    "data_chg_pred_occ_t_8 = calculate_occupancy_rate(data_chg_8)\n",
    "data_chg_pred_occ_t_9 = calculate_occupancy_rate(data_chg_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      weekday   weekend\n",
       "0    0.018519  0.142857\n",
       "1    0.018519  0.000000\n",
       "2    0.018519  0.000000\n",
       "3    0.018519  0.142857\n",
       "4    0.000000  0.142857\n",
       "..        ...       ...\n",
       "139  0.000000  0.142857\n",
       "140  0.018519  0.142857\n",
       "141  0.018519  0.142857\n",
       "142  0.018519  0.285714\n",
       "143  0.018519  0.142857\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chg_pred_occ_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_pred_occ_t_1 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_1.csv')\n",
    "chg_pred_occ_t_2 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_2.csv')\n",
    "chg_pred_occ_t_3 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_3.csv')\n",
    "chg_pred_occ_t_4 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_4.csv')\n",
    "chg_pred_occ_t_5 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_5.csv')\n",
    "chg_pred_occ_t_6 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_6.csv')\n",
    "chg_pred_occ_t_7 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_7.csv')\n",
    "chg_pred_occ_t_8 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_8.csv')\n",
    "chg_pred_occ_t_9 = pd.read_csv('data/data_chg_pred_occ_t/data_chg_pred_occ_t_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diff rows is: 103\n",
      "Number of diff rows is: 144\n",
      "Number of diff rows is: 144\n",
      "Number of diff rows is: 143\n",
      "Number of diff rows is: 143\n",
      "Number of diff rows is: 144\n",
      "Number of diff rows is: 144\n",
      "Number of diff rows is: 144\n",
      "Number of diff rows is: 144\n"
     ]
    }
   ],
   "source": [
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_1, chg_pred_occ_t_1)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_2, chg_pred_occ_t_2)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_3, chg_pred_occ_t_3)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_4, chg_pred_occ_t_4)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_5, chg_pred_occ_t_5)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_6, chg_pred_occ_t_6)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_7, chg_pred_occ_t_7)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_8, chg_pred_occ_t_8)\n",
    "reset_index_and_compare_dfs(data_chg_pred_occ_t_9, chg_pred_occ_t_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store the Dataframes in csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8784\n",
      "13104\n",
      "12672\n",
      "12816\n",
      "13104\n",
      "8496\n",
      "8496\n",
      "8496\n",
      "8496\n"
     ]
    }
   ],
   "source": [
    "# Obtain the charging data\n",
    "data_frames = [\n",
    "    (process_charging_data(df_1)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_1.csv'),\n",
    "    (process_charging_data(df_2)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_2.csv'),\n",
    "    (process_charging_data(df_3)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_3.csv'),\n",
    "    (process_charging_data(df_4)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_4.csv'),\n",
    "    (process_charging_data(df_5)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_5.csv'),\n",
    "    (process_charging_data(df_6)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_6.csv'),\n",
    "    (process_charging_data(df_7)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_7.csv'),\n",
    "    (process_charging_data(df_8)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_8.csv'),\n",
    "    (process_charging_data(df_9)[['t', 'dayofweek', 'weekend', 'y_t_1', 'y']], 'data/nikos_data/data_chg_9.csv')\n",
    "]\n",
    "\n",
    "for df, filename in data_frames:\n",
    "    df.to_csv(filename, index=False)  # Save to CSV without row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the occupancy rate profiles for each DataFrame\n",
    "data_chg_pred_occ_t_list = [\n",
    "    (calculate_occupancy_rate(data_chg_1), 'data/nikos_data/data_chg_pred_occ_t_1.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_2), 'data/nikos_data/data_chg_pred_occ_t_2.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_3), 'data/nikos_data/data_chg_pred_occ_t_3.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_4), 'data/nikos_data/data_chg_pred_occ_t_4.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_5), 'data/nikos_data/data_chg_pred_occ_t_5.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_6), 'data/nikos_data/data_chg_pred_occ_t_6.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_7), 'data/nikos_data/data_chg_pred_occ_t_7.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_8), 'data/nikos_data/data_chg_pred_occ_t_8.csv'),\n",
    "    (calculate_occupancy_rate(data_chg_9), 'data/nikos_data/data_chg_pred_occ_t_9.csv')\n",
    "]\n",
    "\n",
    "for df, filename in data_chg_pred_occ_t_list:\n",
    "    df.to_csv(filename, index=False)  # Save to CSV without row indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
