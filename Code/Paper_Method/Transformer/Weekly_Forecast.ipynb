{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239 entries, 0 to 238\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           239 non-null    datetime64[ns]\n",
      " 1   Energy__kWh_   239 non-null    float64       \n",
      " 2   Day            239 non-null    int64         \n",
      " 3   Minimum T      239 non-null    int64         \n",
      " 4   Maximum T      239 non-null    int64         \n",
      " 5   Snow           239 non-null    float64       \n",
      " 6   Precipitation  239 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(3)\n",
      "memory usage: 13.2 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from Transformer import *\n",
    "\n",
    "# Import the utils from the Time2Vec Transformer\n",
    "import sys\n",
    "sys.path.append(\"../Time2Vec\")\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "weekly = pd.read_csv('../../../Dataset/Boulder_Weekly.csv')\n",
    "weekly['Date'] = pd.to_datetime(weekly['Date'])\n",
    "weekly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataset accord to date, extract the mothns from the 'Date' column and drop it\n",
    "if weekly['Date'].is_monotonic_increasing == False:\n",
    "    weekly.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "weekly['Month'] = weekly['Date'].dt.month_name()\n",
    "weekly.drop(columns={'Date', 'Day'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Scale the Dataset with MinMaxScaler / One-Hot Encode and Extract the Entire Scaled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy__kWh_', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation',\n",
       "       'Month_April', 'Month_August', 'Month_December', 'Month_February',\n",
       "       'Month_January', 'Month_July', 'Month_June', 'Month_March', 'Month_May',\n",
       "       'Month_November', 'Month_October', 'Month_September'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns we need to scale\n",
    "columns_to_scale = ['Energy__kWh_', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation']\n",
    "\n",
    "# MinMax scaling for numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "weekly_scaled = weekly.copy()\n",
    "weekly_scaled[columns_to_scale] = scaler.fit_transform(weekly[columns_to_scale])\n",
    "\n",
    "# Define the columns we need to use for One-Hot Encoding\n",
    "categorical_columns = ['Month']\n",
    "\n",
    "# One-hot encoding for 'Weekday' and 'Month'\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "categorical_encoded = onehot_encoder.fit_transform(weekly[categorical_columns])\n",
    "\n",
    "# Get the feature names from the encoder\n",
    "encoded_columns = []\n",
    "for col, values in zip(categorical_columns, onehot_encoder.categories_):\n",
    "    encoded_columns.extend([f'{col}_{value}' for value in values])\n",
    "\n",
    "# Create DataFrame with encoded columns\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=encoded_columns)\n",
    "\n",
    "# Concatenate the new encoded columns to the original DataFrame\n",
    "weekly_scaled = pd.concat([weekly_scaled, categorical_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "weekly_scaled = weekly_scaled.drop(categorical_columns, axis=1)\n",
    "weekly_scaled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Divided the dataset into training, testing, and validation datasets according to 0.70, 0.20, and 0.10, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split ratio:   0.699\n",
      "Validation split ratio: 0.197\n",
      "Testing split ratio:    0.105\n",
      "\n",
      "Shapes of the datasets:\n",
      "(167, 17) (47, 17) (25, 17)\n"
     ]
    }
   ],
   "source": [
    "train_weekly_scaled, val_weekly_scaled, test_weekly_scaled = split_dataset(weekly_scaled, train_ratio=0.7, val_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create sequences for the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into sequences:\n",
      "Sequences shape: (149, 18, 17)\n",
      "Targets shape: (149,)\n",
      "\n",
      "Dataset split into sequences:\n",
      "Sequences shape: (29, 18, 17)\n",
      "Targets shape: (29,)\n",
      "\n",
      "Dataset split into sequences:\n",
      "Sequences shape: (7, 18, 17)\n",
      "Targets shape: (7,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 18\n",
    "num_features = len(weekly_scaled.columns)\n",
    "\n",
    "# Create the training, validation, and test data sequences\n",
    "train_data_inputs, train_data_targets = create_sequences(train_weekly_scaled, sequence_length)\n",
    "val_data_inputs, val_data_targets = create_sequences(val_weekly_scaled, sequence_length)\n",
    "test_data_inputs, test_data_targets = create_sequences(test_weekly_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create the Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 18, 17)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, None, 17)    1224        ['input_7[0][0]',                \n",
      " HeadAttention)                                                   'input_7[0][0]',                \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, None, 17)     0           ['multi_head_attention_56[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 18, 17)      0           ['input_7[0][0]',                \n",
      " ambda)                                                           'dropout_120[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 18, 17)      34          ['tf.__operators__.add_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " positionwise_feed_forward_20 (  (None, 18, 17)      2257        ['layer_normalization_94[0][0]'] \n",
      " PositionwiseFeedForward)                                                                         \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 18, 17)       0           ['positionwise_feed_forward_20[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 18, 17)      0           ['layer_normalization_94[0][0]', \n",
      " ambda)                                                           'dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 18, 17)      34          ['tf.__operators__.add_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, None, 17)    1224        ['layer_normalization_95[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_95[0][0]', \n",
      "                                                                  'layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, None, 17)     0           ['multi_head_attention_61[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 18, 17)      0           ['dropout_131[0][0]',            \n",
      " ambda)                                                           'layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 18, 17)      34          ['tf.__operators__.add_57[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, None, 17)    1224        ['layer_normalization_102[0][0]',\n",
      " HeadAttention)                                                   'input_7[0][0]',                \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, None, 17)     0           ['multi_head_attention_62[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 18, 17)      0           ['layer_normalization_102[0][0]',\n",
      " ambda)                                                           'dropout_132[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 18, 17)      34          ['tf.__operators__.add_58[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " positionwise_feed_forward_23 (  (None, 18, 17)      2257        ['layer_normalization_103[0][0]']\n",
      " PositionwiseFeedForward)                                                                         \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 18, 17)       0           ['positionwise_feed_forward_23[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 18, 17)      0           ['layer_normalization_103[0][0]',\n",
      " ambda)                                                           'dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 18, 17)      34          ['tf.__operators__.add_59[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 18)          0           ['layer_normalization_104[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 18)           0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_234 (Dense)              (None, 1)            19          ['dropout_135[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,375\n",
      "Trainable params: 8,375\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters of the manual model\n",
    "num_heads = 1\n",
    "d_ff = 64\n",
    "num_layers = 3\n",
    "dropout_rate = 0.1\n",
    "encoder_mask = None\n",
    "decoder_mask = tf.linalg.band_part(tf.ones((sequence_length, sequence_length)), -1, 0)  # Create a lower triangular mask\n",
    "decoder_mask = 1 - decoder_mask  # Invert the mask\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   manual_model = main(sequence_length, num_features, num_heads, d_ff, num_layers, dropout_rate, encoder_mask, decoder_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 18, 17)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 18, 17)      1295        ['input_8[0][0]',                \n",
      " HeadAttention)                                                   'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 18, 17)       0           ['multi_head_attention_63[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 18, 17)      34          ['dropout_136[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_42 (Sequential)     (None, 18, 18)       2322        ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 18, 18)       0           ['sequential_42[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 18, 18)      36          ['dropout_137[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_64 (Multi  (None, 18, 18)      1368        ['layer_normalization_106[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_64[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 18, 18)      36          ['dropout_138[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_43 (Sequential)     (None, 18, 18)       2386        ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 18, 18)       0           ['sequential_43[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 18, 18)      36          ['dropout_139[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_65 (Multi  (None, 18, 18)      1368        ['layer_normalization_108[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 18, 18)      36          ['dropout_140[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_44 (Sequential)     (None, 18, 18)       2386        ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 18, 18)       0           ['sequential_44[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 18, 18)      36          ['dropout_141[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_66 (Multi  (None, 18, 18)      1368        ['layer_normalization_110[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_66[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 18, 18)      36          ['dropout_142[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_67 (Multi  (None, 18, 18)      1368        ['layer_normalization_111[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_67[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 18, 18)      36          ['dropout_143[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_45 (Sequential)     (None, 18, 18)       2386        ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 18, 18)       0           ['sequential_45[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 18, 18)      36          ['dropout_144[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_68 (Multi  (None, 18, 18)      1368        ['layer_normalization_113[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_68[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 18, 18)      36          ['dropout_145[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_69 (Multi  (None, 18, 18)      1368        ['layer_normalization_114[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_69[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 18, 18)      36          ['dropout_146[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_46 (Sequential)     (None, 18, 18)       2386        ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 18, 18)       0           ['sequential_46[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 18, 18)      36          ['dropout_147[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_70 (Multi  (None, 18, 18)      1368        ['layer_normalization_116[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_70[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 18, 18)      36          ['dropout_148[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_71 (Multi  (None, 18, 18)      1368        ['layer_normalization_117[0][0]',\n",
      " HeadAttention)                                                   'layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 18, 18)       0           ['multi_head_attention_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 18, 18)      36          ['dropout_149[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential_47 (Sequential)     (None, 18, 18)       2386        ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 18, 18)       0           ['sequential_47[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 18, 18)      36          ['dropout_150[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 18)          0           ['layer_normalization_119[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 18)           0           ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_247 (Dense)              (None, 1)            19          ['dropout_151[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,048\n",
      "Trainable params: 27,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the transformer model\n",
    "input_shape = (sequence_length, num_features)\n",
    "keras_model = keras_transformer_model(input_shape, num_heads, d_ff, num_layers, dropout_rate)\n",
    "\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compile the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate for Adam optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Compile the manual model\n",
    "manual_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse',  metrics=['mae', 'mse', root_mean_squared_error])\n",
    "\n",
    "# Compile the keras model\n",
    "keras_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse',  metrics=['mae', 'mse', root_mean_squared_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149, 18, 17), (149,), (29, 18, 17), (29,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters for training\n",
    "epochs = 200\n",
    "batch_size = 512\n",
    "\n",
    "# Convert the data to float32\n",
    "train_data_inputs = train_data_inputs.astype('float32')\n",
    "train_data_targets = train_data_targets.astype('float32')\n",
    "\n",
    "val_data_inputs = val_data_inputs.astype('float32')\n",
    "val_data_targets = val_data_targets.astype('float32')\n",
    "\n",
    "train_data_inputs.shape, train_data_targets.shape, val_data_inputs.shape, val_data_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 0.0848 - mae: 0.2600 - mse: 0.0848 - root_mean_squared_error: 0.2912 - val_loss: 0.2681 - val_mae: 0.5131 - val_mse: 0.2681 - val_root_mean_squared_error: 0.5178\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0768 - mae: 0.2448 - mse: 0.0768 - root_mean_squared_error: 0.2772 - val_loss: 0.2466 - val_mae: 0.4918 - val_mse: 0.2466 - val_root_mean_squared_error: 0.4966\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0672 - mae: 0.2265 - mse: 0.0672 - root_mean_squared_error: 0.2593 - val_loss: 0.2202 - val_mae: 0.4641 - val_mse: 0.2202 - val_root_mean_squared_error: 0.4692\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0561 - mae: 0.1989 - mse: 0.0561 - root_mean_squared_error: 0.2369 - val_loss: 0.1897 - val_mae: 0.4300 - val_mse: 0.1897 - val_root_mean_squared_error: 0.4355\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0433 - mae: 0.1696 - mse: 0.0433 - root_mean_squared_error: 0.2081 - val_loss: 0.1564 - val_mae: 0.3894 - val_mse: 0.1564 - val_root_mean_squared_error: 0.3955\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0337 - mae: 0.1412 - mse: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.1220 - val_mae: 0.3424 - val_mse: 0.1220 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0252 - mae: 0.1274 - mse: 0.0252 - root_mean_squared_error: 0.1587 - val_loss: 0.0885 - val_mae: 0.2893 - val_mse: 0.0885 - val_root_mean_squared_error: 0.2974\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0216 - mae: 0.1244 - mse: 0.0216 - root_mean_squared_error: 0.1470 - val_loss: 0.0597 - val_mae: 0.2347 - val_mse: 0.0597 - val_root_mean_squared_error: 0.2444\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0208 - mae: 0.1216 - mse: 0.0208 - root_mean_squared_error: 0.1443 - val_loss: 0.0452 - val_mae: 0.2018 - val_mse: 0.0452 - val_root_mean_squared_error: 0.2125\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0256 - mae: 0.1334 - mse: 0.0256 - root_mean_squared_error: 0.1600 - val_loss: 0.0516 - val_mae: 0.2175 - val_mse: 0.0516 - val_root_mean_squared_error: 0.2273\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0206 - mae: 0.1196 - mse: 0.0206 - root_mean_squared_error: 0.1435 - val_loss: 0.0745 - val_mae: 0.2644 - val_mse: 0.0745 - val_root_mean_squared_error: 0.2730\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0183 - mae: 0.1111 - mse: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0898 - val_mae: 0.2907 - val_mse: 0.0898 - val_root_mean_squared_error: 0.2997\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0186 - mae: 0.1110 - mse: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0764 - val_mae: 0.2645 - val_mse: 0.0764 - val_root_mean_squared_error: 0.2764\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0181 - mae: 0.1113 - mse: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0551 - val_mae: 0.2176 - val_mse: 0.0551 - val_root_mean_squared_error: 0.2348\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0167 - mae: 0.1050 - mse: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0485 - val_mae: 0.2002 - val_mse: 0.0485 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0170 - mae: 0.1116 - mse: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0587 - val_mae: 0.2240 - val_mse: 0.0587 - val_root_mean_squared_error: 0.2424\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0146 - mae: 0.1019 - mse: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0671 - val_mae: 0.2419 - val_mse: 0.0671 - val_root_mean_squared_error: 0.2590\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0156 - mae: 0.1025 - mse: 0.0156 - root_mean_squared_error: 0.1248 - val_loss: 0.0590 - val_mae: 0.2230 - val_mse: 0.0590 - val_root_mean_squared_error: 0.2429\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0151 - mae: 0.0996 - mse: 0.0151 - root_mean_squared_error: 0.1228 - val_loss: 0.0429 - val_mae: 0.1812 - val_mse: 0.0429 - val_root_mean_squared_error: 0.2071\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0124 - mae: 0.0898 - mse: 0.0124 - root_mean_squared_error: 0.1112 - val_loss: 0.0280 - val_mae: 0.1389 - val_mse: 0.0280 - val_root_mean_squared_error: 0.1672\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0123 - mae: 0.0911 - mse: 0.0123 - root_mean_squared_error: 0.1109 - val_loss: 0.0234 - val_mae: 0.1240 - val_mse: 0.0234 - val_root_mean_squared_error: 0.1529\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0126 - mae: 0.0912 - mse: 0.0126 - root_mean_squared_error: 0.1124 - val_loss: 0.0267 - val_mae: 0.1313 - val_mse: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0118 - mae: 0.0852 - mse: 0.0118 - root_mean_squared_error: 0.1087 - val_loss: 0.0228 - val_mae: 0.1171 - val_mse: 0.0228 - val_root_mean_squared_error: 0.1509\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0116 - mae: 0.0845 - mse: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0132 - val_mae: 0.0843 - val_mse: 0.0132 - val_root_mean_squared_error: 0.1151\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0110 - mae: 0.0813 - mse: 0.0110 - root_mean_squared_error: 0.1047 - val_loss: 0.0092 - val_mae: 0.0693 - val_mse: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0102 - mae: 0.0797 - mse: 0.0102 - root_mean_squared_error: 0.1009 - val_loss: 0.0094 - val_mae: 0.0714 - val_mse: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0094 - mae: 0.0735 - mse: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0106 - val_mae: 0.0785 - val_mse: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0720 - mse: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0106 - val_mae: 0.0816 - val_mse: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.0725 - mse: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0095 - val_mae: 0.0793 - val_mse: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0714 - mse: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0096 - val_mae: 0.0808 - val_mse: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.0718 - mse: 0.0094 - root_mean_squared_error: 0.0967 - val_loss: 0.0152 - val_mae: 0.1063 - val_mse: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0071 - mae: 0.0665 - mse: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0193 - val_mae: 0.1217 - val_mse: 0.0193 - val_root_mean_squared_error: 0.1390\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0075 - mae: 0.0679 - mse: 0.0075 - root_mean_squared_error: 0.0868 - val_loss: 0.0178 - val_mae: 0.1168 - val_mse: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0069 - mae: 0.0625 - mse: 0.0069 - root_mean_squared_error: 0.0828 - val_loss: 0.0148 - val_mae: 0.1060 - val_mse: 0.0148 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0071 - mae: 0.0645 - mse: 0.0071 - root_mean_squared_error: 0.0844 - val_loss: 0.0146 - val_mae: 0.1054 - val_mse: 0.0146 - val_root_mean_squared_error: 0.1208\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - mae: 0.0607 - mse: 0.0066 - root_mean_squared_error: 0.0810 - val_loss: 0.0160 - val_mae: 0.1110 - val_mse: 0.0160 - val_root_mean_squared_error: 0.1266\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0553 - mse: 0.0053 - root_mean_squared_error: 0.0727 - val_loss: 0.0176 - val_mae: 0.1166 - val_mse: 0.0176 - val_root_mean_squared_error: 0.1325\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063 - mae: 0.0588 - mse: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0186 - val_mae: 0.1201 - val_mse: 0.0186 - val_root_mean_squared_error: 0.1362\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0626 - mse: 0.0068 - root_mean_squared_error: 0.0826 - val_loss: 0.0182 - val_mae: 0.1189 - val_mse: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0052 - mae: 0.0551 - mse: 0.0052 - root_mean_squared_error: 0.0722 - val_loss: 0.0154 - val_mae: 0.1089 - val_mse: 0.0154 - val_root_mean_squared_error: 0.1240\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0056 - mae: 0.0564 - mse: 0.0056 - root_mean_squared_error: 0.0746 - val_loss: 0.0142 - val_mae: 0.1043 - val_mse: 0.0142 - val_root_mean_squared_error: 0.1192\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0053 - mae: 0.0535 - mse: 0.0053 - root_mean_squared_error: 0.0731 - val_loss: 0.0159 - val_mae: 0.1112 - val_mse: 0.0159 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0061 - mae: 0.0567 - mse: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0200 - val_mae: 0.1253 - val_mse: 0.0200 - val_root_mean_squared_error: 0.1414\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0050 - mae: 0.0540 - mse: 0.0050 - root_mean_squared_error: 0.0705 - val_loss: 0.0226 - val_mae: 0.1339 - val_mse: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0055 - mae: 0.0564 - mse: 0.0055 - root_mean_squared_error: 0.0742 - val_loss: 0.0223 - val_mae: 0.1327 - val_mse: 0.0223 - val_root_mean_squared_error: 0.1492\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0055 - mae: 0.0565 - mse: 0.0055 - root_mean_squared_error: 0.0743 - val_loss: 0.0197 - val_mae: 0.1243 - val_mse: 0.0197 - val_root_mean_squared_error: 0.1402\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0049 - mae: 0.0521 - mse: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0181 - val_mae: 0.1192 - val_mse: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0045 - mae: 0.0490 - mse: 0.0045 - root_mean_squared_error: 0.0673 - val_loss: 0.0179 - val_mae: 0.1185 - val_mse: 0.0179 - val_root_mean_squared_error: 0.1339\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0053 - mae: 0.0519 - mse: 0.0053 - root_mean_squared_error: 0.0728 - val_loss: 0.0197 - val_mae: 0.1244 - val_mse: 0.0197 - val_root_mean_squared_error: 0.1404\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0047 - mae: 0.0519 - mse: 0.0047 - root_mean_squared_error: 0.0684 - val_loss: 0.0214 - val_mae: 0.1299 - val_mse: 0.0214 - val_root_mean_squared_error: 0.1463\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - mae: 0.0517 - mse: 0.0045 - root_mean_squared_error: 0.0669 - val_loss: 0.0222 - val_mae: 0.1325 - val_mse: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0043 - mae: 0.0492 - mse: 0.0043 - root_mean_squared_error: 0.0656 - val_loss: 0.0199 - val_mae: 0.1249 - val_mse: 0.0199 - val_root_mean_squared_error: 0.1412\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0046 - mae: 0.0499 - mse: 0.0046 - root_mean_squared_error: 0.0676 - val_loss: 0.0166 - val_mae: 0.1134 - val_mse: 0.0166 - val_root_mean_squared_error: 0.1288\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0040 - mae: 0.0492 - mse: 0.0040 - root_mean_squared_error: 0.0636 - val_loss: 0.0144 - val_mae: 0.1050 - val_mse: 0.0144 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0051 - mae: 0.0529 - mse: 0.0051 - root_mean_squared_error: 0.0713 - val_loss: 0.0150 - val_mae: 0.1070 - val_mse: 0.0150 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0043 - mae: 0.0493 - mse: 0.0043 - root_mean_squared_error: 0.0653 - val_loss: 0.0156 - val_mae: 0.1095 - val_mse: 0.0156 - val_root_mean_squared_error: 0.1249\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0054 - mae: 0.0534 - mse: 0.0054 - root_mean_squared_error: 0.0733 - val_loss: 0.0161 - val_mae: 0.1115 - val_mse: 0.0161 - val_root_mean_squared_error: 0.1271\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - mae: 0.0488 - mse: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0160 - val_mae: 0.1110 - val_mse: 0.0160 - val_root_mean_squared_error: 0.1265\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0042 - mae: 0.0475 - mse: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0163 - val_mae: 0.1122 - val_mse: 0.0163 - val_root_mean_squared_error: 0.1276\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - mae: 0.0442 - mse: 0.0038 - root_mean_squared_error: 0.0618 - val_loss: 0.0164 - val_mae: 0.1126 - val_mse: 0.0164 - val_root_mean_squared_error: 0.1280\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0049 - mae: 0.0510 - mse: 0.0049 - root_mean_squared_error: 0.0702 - val_loss: 0.0179 - val_mae: 0.1180 - val_mse: 0.0179 - val_root_mean_squared_error: 0.1338\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0042 - mae: 0.0447 - mse: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0198 - val_mae: 0.1244 - val_mse: 0.0198 - val_root_mean_squared_error: 0.1406\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - mae: 0.0494 - mse: 0.0044 - root_mean_squared_error: 0.0662 - val_loss: 0.0188 - val_mae: 0.1209 - val_mse: 0.0188 - val_root_mean_squared_error: 0.1372\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0036 - mae: 0.0441 - mse: 0.0036 - root_mean_squared_error: 0.0602 - val_loss: 0.0159 - val_mae: 0.1105 - val_mse: 0.0159 - val_root_mean_squared_error: 0.1260\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - mae: 0.0447 - mse: 0.0037 - root_mean_squared_error: 0.0608 - val_loss: 0.0140 - val_mae: 0.1030 - val_mse: 0.0140 - val_root_mean_squared_error: 0.1183\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0039 - mae: 0.0448 - mse: 0.0039 - root_mean_squared_error: 0.0628 - val_loss: 0.0128 - val_mae: 0.0979 - val_mse: 0.0128 - val_root_mean_squared_error: 0.1133\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0427 - mse: 0.0037 - root_mean_squared_error: 0.0605 - val_loss: 0.0146 - val_mae: 0.1051 - val_mse: 0.0146 - val_root_mean_squared_error: 0.1207\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - mae: 0.0443 - mse: 0.0038 - root_mean_squared_error: 0.0618 - val_loss: 0.0152 - val_mae: 0.1076 - val_mse: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0031 - mae: 0.0398 - mse: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0152 - val_mae: 0.1074 - val_mse: 0.0152 - val_root_mean_squared_error: 0.1232\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0035 - mae: 0.0413 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0143 - val_mae: 0.1040 - val_mse: 0.0143 - val_root_mean_squared_error: 0.1197\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - mae: 0.0437 - mse: 0.0037 - root_mean_squared_error: 0.0608 - val_loss: 0.0159 - val_mae: 0.1101 - val_mse: 0.0159 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0414 - mse: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0174 - val_mae: 0.1151 - val_mse: 0.0174 - val_root_mean_squared_error: 0.1317\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0038 - mae: 0.0440 - mse: 0.0038 - root_mean_squared_error: 0.0613 - val_loss: 0.0164 - val_mae: 0.1115 - val_mse: 0.0164 - val_root_mean_squared_error: 0.1281\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0034 - mae: 0.0423 - mse: 0.0034 - root_mean_squared_error: 0.0579 - val_loss: 0.0144 - val_mae: 0.1040 - val_mse: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0382 - mse: 0.0028 - root_mean_squared_error: 0.0532 - val_loss: 0.0134 - val_mae: 0.0995 - val_mse: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0408 - mse: 0.0031 - root_mean_squared_error: 0.0555 - val_loss: 0.0130 - val_mae: 0.0975 - val_mse: 0.0130 - val_root_mean_squared_error: 0.1139\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - mae: 0.0405 - mse: 0.0032 - root_mean_squared_error: 0.0566 - val_loss: 0.0131 - val_mae: 0.0976 - val_mse: 0.0131 - val_root_mean_squared_error: 0.1143\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0416 - mse: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0116 - val_mae: 0.0908 - val_mse: 0.0116 - val_root_mean_squared_error: 0.1077\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0028 - mae: 0.0392 - mse: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0103 - val_mae: 0.0845 - val_mse: 0.0103 - val_root_mean_squared_error: 0.1015\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0032 - mae: 0.0415 - mse: 0.0032 - root_mean_squared_error: 0.0562 - val_loss: 0.0113 - val_mae: 0.0897 - val_mse: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - mae: 0.0407 - mse: 0.0030 - root_mean_squared_error: 0.0552 - val_loss: 0.0143 - val_mae: 0.1023 - val_mse: 0.0143 - val_root_mean_squared_error: 0.1195\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0030 - mae: 0.0399 - mse: 0.0030 - root_mean_squared_error: 0.0543 - val_loss: 0.0161 - val_mae: 0.1091 - val_mse: 0.0161 - val_root_mean_squared_error: 0.1268\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0029 - mae: 0.0375 - mse: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0138 - val_mae: 0.1006 - val_mse: 0.0138 - val_root_mean_squared_error: 0.1175\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0387 - mse: 0.0030 - root_mean_squared_error: 0.0548 - val_loss: 0.0123 - val_mae: 0.0938 - val_mse: 0.0123 - val_root_mean_squared_error: 0.1107\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - mae: 0.0417 - mse: 0.0032 - root_mean_squared_error: 0.0569 - val_loss: 0.0130 - val_mae: 0.0969 - val_mse: 0.0130 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0390 - mse: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.0150 - val_mae: 0.1048 - val_mse: 0.0150 - val_root_mean_squared_error: 0.1225\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0363 - mse: 0.0027 - root_mean_squared_error: 0.0516 - val_loss: 0.0143 - val_mae: 0.1018 - val_mse: 0.0143 - val_root_mean_squared_error: 0.1194\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - mae: 0.0367 - mse: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0111 - val_mae: 0.0879 - val_mse: 0.0111 - val_root_mean_squared_error: 0.1052\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - mae: 0.0362 - mse: 0.0025 - root_mean_squared_error: 0.0503 - val_loss: 0.0099 - val_mae: 0.0820 - val_mse: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0027 - mae: 0.0375 - mse: 0.0027 - root_mean_squared_error: 0.0519 - val_loss: 0.0098 - val_mae: 0.0813 - val_mse: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0030 - mae: 0.0388 - mse: 0.0030 - root_mean_squared_error: 0.0545 - val_loss: 0.0109 - val_mae: 0.0861 - val_mse: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0035 - mae: 0.0423 - mse: 0.0035 - root_mean_squared_error: 0.0594 - val_loss: 0.0129 - val_mae: 0.0948 - val_mse: 0.0129 - val_root_mean_squared_error: 0.1134\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0031 - mae: 0.0406 - mse: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0111 - val_mae: 0.0872 - val_mse: 0.0111 - val_root_mean_squared_error: 0.1054\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - mae: 0.0389 - mse: 0.0030 - root_mean_squared_error: 0.0550 - val_loss: 0.0093 - val_mae: 0.0789 - val_mse: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0027 - mae: 0.0388 - mse: 0.0027 - root_mean_squared_error: 0.0523 - val_loss: 0.0112 - val_mae: 0.0879 - val_mse: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0407 - mse: 0.0031 - root_mean_squared_error: 0.0555 - val_loss: 0.0139 - val_mae: 0.0995 - val_mse: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0027 - mae: 0.0374 - mse: 0.0027 - root_mean_squared_error: 0.0515 - val_loss: 0.0139 - val_mae: 0.0994 - val_mse: 0.0139 - val_root_mean_squared_error: 0.1179\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0027 - mae: 0.0383 - mse: 0.0027 - root_mean_squared_error: 0.0516 - val_loss: 0.0117 - val_mae: 0.0900 - val_mse: 0.0117 - val_root_mean_squared_error: 0.1083\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0028 - mae: 0.0374 - mse: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0103 - val_mae: 0.0826 - val_mse: 0.0103 - val_root_mean_squared_error: 0.1013\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - mae: 0.0411 - mse: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0087 - val_mae: 0.0748 - val_mse: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - mae: 0.0396 - mse: 0.0030 - root_mean_squared_error: 0.0544 - val_loss: 0.0092 - val_mae: 0.0772 - val_mse: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0024 - mae: 0.0357 - mse: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0097 - val_mae: 0.0799 - val_mse: 0.0097 - val_root_mean_squared_error: 0.0986\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0026 - mae: 0.0386 - mse: 0.0026 - root_mean_squared_error: 0.0509 - val_loss: 0.0106 - val_mae: 0.0844 - val_mse: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0357 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0112 - val_mae: 0.0872 - val_mse: 0.0112 - val_root_mean_squared_error: 0.1060\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0347 - mse: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 0.0103 - val_mae: 0.0832 - val_mse: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0024 - mae: 0.0367 - mse: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0114 - val_mae: 0.0876 - val_mse: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0029 - mae: 0.0373 - mse: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0127 - val_mae: 0.0930 - val_mse: 0.0127 - val_root_mean_squared_error: 0.1125\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0024 - mae: 0.0343 - mse: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0078 - val_mae: 0.0696 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0020 - mae: 0.0326 - mse: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0070 - val_mae: 0.0653 - val_mse: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0372 - mse: 0.0025 - root_mean_squared_error: 0.0498 - val_loss: 0.0091 - val_mae: 0.0764 - val_mse: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0099 - val_mae: 0.0802 - val_mse: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0022 - mae: 0.0341 - mse: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0099 - val_mae: 0.0801 - val_mse: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0024 - mae: 0.0382 - mse: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0068 - val_mae: 0.0647 - val_mse: 0.0068 - val_root_mean_squared_error: 0.0824\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0025 - mae: 0.0349 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0064 - val_mae: 0.0618 - val_mse: 0.0064 - val_root_mean_squared_error: 0.0797\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0022 - mae: 0.0347 - mse: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0078 - val_mae: 0.0699 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0029 - mae: 0.0376 - mse: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0068 - val_mae: 0.0642 - val_mse: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0020 - mae: 0.0331 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0070 - val_mae: 0.0664 - val_mse: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0364 - mse: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0107 - val_mae: 0.0851 - val_mse: 0.0107 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0019 - mae: 0.0335 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0123 - val_mae: 0.0931 - val_mse: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0025 - mae: 0.0364 - mse: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0088 - val_mae: 0.0758 - val_mse: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0020 - mae: 0.0305 - mse: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 0.0060 - val_mae: 0.0615 - val_mse: 0.0060 - val_root_mean_squared_error: 0.0773\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0075 - val_mae: 0.0693 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0344 - mse: 0.0021 - root_mean_squared_error: 0.0457 - val_loss: 0.0104 - val_mae: 0.0844 - val_mse: 0.0104 - val_root_mean_squared_error: 0.1019\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - root_mean_squared_error: 0.0480 - val_loss: 0.0085 - val_mae: 0.0751 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0924\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0018 - root_mean_squared_error: 0.0427 - val_loss: 0.0080 - val_mae: 0.0723 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0024 - mae: 0.0378 - mse: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0096 - val_mae: 0.0797 - val_mse: 0.0096 - val_root_mean_squared_error: 0.0978\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0139 - val_mae: 0.1005 - val_mse: 0.0139 - val_root_mean_squared_error: 0.1177\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0144 - val_mae: 0.1029 - val_mse: 0.0144 - val_root_mean_squared_error: 0.1201\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0023 - mae: 0.0368 - mse: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0094 - val_mae: 0.0786 - val_mse: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0019 - mae: 0.0330 - mse: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0073 - val_mae: 0.0682 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0022 - mae: 0.0362 - mse: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0080 - val_mae: 0.0709 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0017 - mae: 0.0310 - mse: 0.0017 - root_mean_squared_error: 0.0416 - val_loss: 0.0100 - val_mae: 0.0817 - val_mse: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0024 - mae: 0.0350 - mse: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0085 - val_mae: 0.0739 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0024 - mae: 0.0352 - mse: 0.0024 - root_mean_squared_error: 0.0487 - val_loss: 0.0059 - val_mae: 0.0587 - val_mse: 0.0059 - val_root_mean_squared_error: 0.0766\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0021 - root_mean_squared_error: 0.0454 - val_loss: 0.0061 - val_mae: 0.0596 - val_mse: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0020 - mae: 0.0336 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0088 - val_mae: 0.0746 - val_mse: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0018 - mae: 0.0304 - mse: 0.0018 - root_mean_squared_error: 0.0418 - val_loss: 0.0100 - val_mae: 0.0802 - val_mse: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0022 - mae: 0.0352 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0070 - val_mae: 0.0650 - val_mse: 0.0070 - val_root_mean_squared_error: 0.0838\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0060 - val_mae: 0.0597 - val_mse: 0.0060 - val_root_mean_squared_error: 0.0774\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0022 - mae: 0.0359 - mse: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0086 - val_mae: 0.0726 - val_mse: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0098 - val_mae: 0.0799 - val_mse: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0023 - mae: 0.0337 - mse: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0072 - val_mae: 0.0658 - val_mse: 0.0072 - val_root_mean_squared_error: 0.0849\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0020 - mae: 0.0341 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0073 - val_mae: 0.0658 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0021 - mae: 0.0349 - mse: 0.0021 - root_mean_squared_error: 0.0459 - val_loss: 0.0095 - val_mae: 0.0785 - val_mse: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0021 - mae: 0.0340 - mse: 0.0021 - root_mean_squared_error: 0.0459 - val_loss: 0.0110 - val_mae: 0.0861 - val_mse: 0.0110 - val_root_mean_squared_error: 0.1048\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - mae: 0.0308 - mse: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0096 - val_mae: 0.0793 - val_mse: 0.0096 - val_root_mean_squared_error: 0.0981\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - mae: 0.0322 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0089 - val_mae: 0.0757 - val_mse: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0018 - mae: 0.0326 - mse: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0096 - val_mae: 0.0790 - val_mse: 0.0096 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0019 - mae: 0.0331 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0091 - val_mae: 0.0773 - val_mse: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0082 - val_mae: 0.0731 - val_mse: 0.0082 - val_root_mean_squared_error: 0.0908\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0081 - val_mae: 0.0729 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0903\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0085 - val_mae: 0.0747 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0021 - mae: 0.0325 - mse: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0093 - val_mae: 0.0783 - val_mse: 0.0093 - val_root_mean_squared_error: 0.0965\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0294 - mse: 0.0016 - root_mean_squared_error: 0.0396 - val_loss: 0.0085 - val_mae: 0.0742 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0017 - mae: 0.0318 - mse: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0078 - val_mae: 0.0707 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0068 - val_mae: 0.0656 - val_mse: 0.0068 - val_root_mean_squared_error: 0.0826\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0069 - val_mae: 0.0651 - val_mse: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0078 - val_mae: 0.0695 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0018 - mae: 0.0313 - mse: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0079 - val_mae: 0.0699 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - root_mean_squared_error: 0.0401 - val_loss: 0.0076 - val_mae: 0.0683 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0017 - root_mean_squared_error: 0.0414 - val_loss: 0.0078 - val_mae: 0.0692 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0312 - mse: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0087 - val_mae: 0.0738 - val_mse: 0.0087 - val_root_mean_squared_error: 0.0931\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0100 - val_mae: 0.0813 - val_mse: 0.0100 - val_root_mean_squared_error: 0.1001\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0015 - mae: 0.0289 - mse: 0.0015 - root_mean_squared_error: 0.0386 - val_loss: 0.0089 - val_mae: 0.0751 - val_mse: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - mae: 0.0315 - mse: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0062 - val_mae: 0.0622 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - mae: 0.0307 - mse: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0077 - val_mae: 0.0700 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0876\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0014 - mae: 0.0275 - mse: 0.0014 - root_mean_squared_error: 0.0377 - val_loss: 0.0094 - val_mae: 0.0776 - val_mse: 0.0094 - val_root_mean_squared_error: 0.0969\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0019 - mae: 0.0330 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0075 - val_mae: 0.0690 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0014 - mae: 0.0286 - mse: 0.0014 - root_mean_squared_error: 0.0377 - val_loss: 0.0066 - val_mae: 0.0653 - val_mse: 0.0066 - val_root_mean_squared_error: 0.0811\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0019 - mae: 0.0329 - mse: 0.0019 - root_mean_squared_error: 0.0430 - val_loss: 0.0078 - val_mae: 0.0699 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0016 - mae: 0.0306 - mse: 0.0016 - root_mean_squared_error: 0.0406 - val_loss: 0.0089 - val_mae: 0.0758 - val_mse: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0017 - mae: 0.0316 - mse: 0.0017 - root_mean_squared_error: 0.0411 - val_loss: 0.0079 - val_mae: 0.0708 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0886\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 0.0064 - val_mae: 0.0640 - val_mse: 0.0064 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0013 - root_mean_squared_error: 0.0361 - val_loss: 0.0071 - val_mae: 0.0674 - val_mse: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0015 - root_mean_squared_error: 0.0391 - val_loss: 0.0100 - val_mae: 0.0805 - val_mse: 0.0100 - val_root_mean_squared_error: 0.0999\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0095 - val_mae: 0.0781 - val_mse: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - root_mean_squared_error: 0.0435 - val_loss: 0.0069 - val_mae: 0.0665 - val_mse: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0018 - mae: 0.0300 - mse: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0062 - val_mae: 0.0627 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0786\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0015 - mae: 0.0300 - mse: 0.0015 - root_mean_squared_error: 0.0392 - val_loss: 0.0077 - val_mae: 0.0705 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0014 - root_mean_squared_error: 0.0372 - val_loss: 0.0087 - val_mae: 0.0757 - val_mse: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0014 - root_mean_squared_error: 0.0369 - val_loss: 0.0077 - val_mae: 0.0712 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0066 - val_mae: 0.0658 - val_mse: 0.0066 - val_root_mean_squared_error: 0.0815\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0014 - mae: 0.0295 - mse: 0.0014 - root_mean_squared_error: 0.0380 - val_loss: 0.0073 - val_mae: 0.0692 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0291 - mse: 0.0015 - root_mean_squared_error: 0.0390 - val_loss: 0.0078 - val_mae: 0.0718 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - root_mean_squared_error: 0.0414 - val_loss: 0.0068 - val_mae: 0.0664 - val_mse: 0.0068 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0012 - root_mean_squared_error: 0.0339 - val_loss: 0.0061 - val_mae: 0.0619 - val_mse: 0.0061 - val_root_mean_squared_error: 0.0780\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0066 - val_mae: 0.0645 - val_mse: 0.0066 - val_root_mean_squared_error: 0.0813\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0073 - val_mae: 0.0678 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0013 - root_mean_squared_error: 0.0364 - val_loss: 0.0075 - val_mae: 0.0691 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0013 - root_mean_squared_error: 0.0358 - val_loss: 0.0072 - val_mae: 0.0681 - val_mse: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0015 - root_mean_squared_error: 0.0384 - val_loss: 0.0076 - val_mae: 0.0705 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0013 - root_mean_squared_error: 0.0364 - val_loss: 0.0083 - val_mae: 0.0742 - val_mse: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0016 - root_mean_squared_error: 0.0401 - val_loss: 0.0081 - val_mae: 0.0738 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0092 - val_mae: 0.0788 - val_mse: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0017 - mae: 0.0292 - mse: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0105 - val_mae: 0.0848 - val_mse: 0.0105 - val_root_mean_squared_error: 0.1026\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0016 - mae: 0.0314 - mse: 0.0016 - root_mean_squared_error: 0.0403 - val_loss: 0.0084 - val_mae: 0.0740 - val_mse: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0015 - mae: 0.0294 - mse: 0.0015 - root_mean_squared_error: 0.0390 - val_loss: 0.0065 - val_mae: 0.0641 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0807\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0018 - mae: 0.0321 - mse: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 0.0068 - val_mae: 0.0650 - val_mse: 0.0068 - val_root_mean_squared_error: 0.0825\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0016 - mae: 0.0283 - mse: 0.0016 - root_mean_squared_error: 0.0394 - val_loss: 0.0078 - val_mae: 0.0697 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0017 - mae: 0.0310 - mse: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0063 - val_mae: 0.0626 - val_mse: 0.0063 - val_root_mean_squared_error: 0.0796\n"
     ]
    }
   ],
   "source": [
    "# Train the manual model\n",
    "history_manual = manual_model.fit(train_data_inputs, train_data_targets,\n",
    "          validation_data=(val_data_inputs, val_data_targets),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.0848 - mae: 0.2600 - mse: 0.0848 - root_mean_squared_error: 0.2912 - val_loss: 0.2697 - val_mae: 0.5147 - val_mse: 0.2697 - val_root_mean_squared_error: 0.5193\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0782 - mae: 0.2473 - mse: 0.0782 - root_mean_squared_error: 0.2796 - val_loss: 0.2518 - val_mae: 0.4970 - val_mse: 0.2518 - val_root_mean_squared_error: 0.5018\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0705 - mae: 0.2319 - mse: 0.0705 - root_mean_squared_error: 0.2655 - val_loss: 0.2281 - val_mae: 0.4725 - val_mse: 0.2281 - val_root_mean_squared_error: 0.4776\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0583 - mae: 0.2062 - mse: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.1999 - val_mae: 0.4417 - val_mse: 0.1999 - val_root_mean_squared_error: 0.4471\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0509 - mae: 0.1857 - mse: 0.0509 - root_mean_squared_error: 0.2255 - val_loss: 0.1685 - val_mae: 0.4046 - val_mse: 0.1685 - val_root_mean_squared_error: 0.4105\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0407 - mae: 0.1594 - mse: 0.0407 - root_mean_squared_error: 0.2019 - val_loss: 0.1354 - val_mae: 0.3614 - val_mse: 0.1354 - val_root_mean_squared_error: 0.3680\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0334 - mae: 0.1446 - mse: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.1022 - val_mae: 0.3121 - val_mse: 0.1022 - val_root_mean_squared_error: 0.3197\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0247 - mae: 0.1301 - mse: 0.0247 - root_mean_squared_error: 0.1570 - val_loss: 0.0715 - val_mae: 0.2582 - val_mse: 0.0715 - val_root_mean_squared_error: 0.2673\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0245 - mae: 0.1317 - mse: 0.0245 - root_mean_squared_error: 0.1566 - val_loss: 0.0509 - val_mae: 0.2147 - val_mse: 0.0509 - val_root_mean_squared_error: 0.2256\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0237 - mae: 0.1278 - mse: 0.0237 - root_mean_squared_error: 0.1540 - val_loss: 0.0401 - val_mae: 0.1880 - val_mse: 0.0401 - val_root_mean_squared_error: 0.2004\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0315 - mae: 0.1492 - mse: 0.0315 - root_mean_squared_error: 0.1776 - val_loss: 0.0387 - val_mae: 0.1842 - val_mse: 0.0387 - val_root_mean_squared_error: 0.1968\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0282 - mae: 0.1359 - mse: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0450 - val_mae: 0.2004 - val_mse: 0.0450 - val_root_mean_squared_error: 0.2120\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0252 - mae: 0.1285 - mse: 0.0252 - root_mean_squared_error: 0.1587 - val_loss: 0.0570 - val_mae: 0.2285 - val_mse: 0.0570 - val_root_mean_squared_error: 0.2387\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0205 - mae: 0.1208 - mse: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0722 - val_mae: 0.2597 - val_mse: 0.0722 - val_root_mean_squared_error: 0.2687\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0198 - mae: 0.1187 - mse: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0890 - val_mae: 0.2902 - val_mse: 0.0890 - val_root_mean_squared_error: 0.2984\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0210 - mae: 0.1194 - mse: 0.0210 - root_mean_squared_error: 0.1450 - val_loss: 0.1031 - val_mae: 0.3135 - val_mse: 0.1031 - val_root_mean_squared_error: 0.3210\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0197 - mae: 0.1160 - mse: 0.0197 - root_mean_squared_error: 0.1404 - val_loss: 0.1096 - val_mae: 0.3238 - val_mse: 0.1096 - val_root_mean_squared_error: 0.3311\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0205 - mae: 0.1141 - mse: 0.0205 - root_mean_squared_error: 0.1431 - val_loss: 0.1096 - val_mae: 0.3237 - val_mse: 0.1096 - val_root_mean_squared_error: 0.3310\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0202 - mae: 0.1150 - mse: 0.0202 - root_mean_squared_error: 0.1422 - val_loss: 0.1055 - val_mae: 0.3173 - val_mse: 0.1055 - val_root_mean_squared_error: 0.3247\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0197 - mae: 0.1152 - mse: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0994 - val_mae: 0.3076 - val_mse: 0.0994 - val_root_mean_squared_error: 0.3153\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0204 - mae: 0.1183 - mse: 0.0204 - root_mean_squared_error: 0.1430 - val_loss: 0.0924 - val_mae: 0.2960 - val_mse: 0.0924 - val_root_mean_squared_error: 0.3040\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0179 - mae: 0.1153 - mse: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0850 - val_mae: 0.2833 - val_mse: 0.0850 - val_root_mean_squared_error: 0.2916\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0182 - mae: 0.1141 - mse: 0.0182 - root_mean_squared_error: 0.1350 - val_loss: 0.0784 - val_mae: 0.2713 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0211 - mae: 0.1240 - mse: 0.0211 - root_mean_squared_error: 0.1451 - val_loss: 0.0735 - val_mae: 0.2622 - val_mse: 0.0735 - val_root_mean_squared_error: 0.2712\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0175 - mae: 0.1113 - mse: 0.0175 - root_mean_squared_error: 0.1321 - val_loss: 0.0699 - val_mae: 0.2551 - val_mse: 0.0699 - val_root_mean_squared_error: 0.2643\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0187 - mae: 0.1162 - mse: 0.0187 - root_mean_squared_error: 0.1369 - val_loss: 0.0679 - val_mae: 0.2512 - val_mse: 0.0679 - val_root_mean_squared_error: 0.2605\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0193 - mae: 0.1190 - mse: 0.0193 - root_mean_squared_error: 0.1388 - val_loss: 0.0676 - val_mae: 0.2505 - val_mse: 0.0676 - val_root_mean_squared_error: 0.2599\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0193 - mae: 0.1184 - mse: 0.0193 - root_mean_squared_error: 0.1389 - val_loss: 0.0691 - val_mae: 0.2537 - val_mse: 0.0691 - val_root_mean_squared_error: 0.2630\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0190 - mae: 0.1201 - mse: 0.0190 - root_mean_squared_error: 0.1377 - val_loss: 0.0722 - val_mae: 0.2597 - val_mse: 0.0722 - val_root_mean_squared_error: 0.2688\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0169 - mae: 0.1102 - mse: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0760 - val_mae: 0.2669 - val_mse: 0.0760 - val_root_mean_squared_error: 0.2757\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0173 - mae: 0.1136 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0801 - val_mae: 0.2744 - val_mse: 0.0801 - val_root_mean_squared_error: 0.2830\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0183 - mae: 0.1158 - mse: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0841 - val_mae: 0.2816 - val_mse: 0.0841 - val_root_mean_squared_error: 0.2900\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0192 - mae: 0.1165 - mse: 0.0192 - root_mean_squared_error: 0.1384 - val_loss: 0.0878 - val_mae: 0.2881 - val_mse: 0.0878 - val_root_mean_squared_error: 0.2963\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0186 - mae: 0.1156 - mse: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0900 - val_mae: 0.2920 - val_mse: 0.0900 - val_root_mean_squared_error: 0.3001\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0185 - mae: 0.1147 - mse: 0.0185 - root_mean_squared_error: 0.1362 - val_loss: 0.0908 - val_mae: 0.2933 - val_mse: 0.0908 - val_root_mean_squared_error: 0.3013\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0181 - mae: 0.1122 - mse: 0.0181 - root_mean_squared_error: 0.1345 - val_loss: 0.0900 - val_mae: 0.2919 - val_mse: 0.0900 - val_root_mean_squared_error: 0.3000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0191 - mae: 0.1163 - mse: 0.0191 - root_mean_squared_error: 0.1380 - val_loss: 0.0881 - val_mae: 0.2886 - val_mse: 0.0881 - val_root_mean_squared_error: 0.2968\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0195 - mae: 0.1182 - mse: 0.0195 - root_mean_squared_error: 0.1395 - val_loss: 0.0856 - val_mae: 0.2843 - val_mse: 0.0856 - val_root_mean_squared_error: 0.2926\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0181 - mae: 0.1156 - mse: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0828 - val_mae: 0.2793 - val_mse: 0.0828 - val_root_mean_squared_error: 0.2877\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0189 - mae: 0.1174 - mse: 0.0189 - root_mean_squared_error: 0.1373 - val_loss: 0.0803 - val_mae: 0.2748 - val_mse: 0.0803 - val_root_mean_squared_error: 0.2834\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0184 - mae: 0.1165 - mse: 0.0184 - root_mean_squared_error: 0.1356 - val_loss: 0.0781 - val_mae: 0.2707 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2794\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0173 - mae: 0.1128 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0762 - val_mae: 0.2672 - val_mse: 0.0762 - val_root_mean_squared_error: 0.2760\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0181 - mae: 0.1147 - mse: 0.0181 - root_mean_squared_error: 0.1346 - val_loss: 0.0754 - val_mae: 0.2657 - val_mse: 0.0754 - val_root_mean_squared_error: 0.2746\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0183 - mae: 0.1180 - mse: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0753 - val_mae: 0.2655 - val_mse: 0.0753 - val_root_mean_squared_error: 0.2743\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0188 - mae: 0.1177 - mse: 0.0188 - root_mean_squared_error: 0.1369 - val_loss: 0.0763 - val_mae: 0.2674 - val_mse: 0.0763 - val_root_mean_squared_error: 0.2762\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0175 - mae: 0.1137 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0775 - val_mae: 0.2696 - val_mse: 0.0775 - val_root_mean_squared_error: 0.2783\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0185 - mae: 0.1184 - mse: 0.0185 - root_mean_squared_error: 0.1361 - val_loss: 0.0791 - val_mae: 0.2726 - val_mse: 0.0791 - val_root_mean_squared_error: 0.2812\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0182 - mae: 0.1157 - mse: 0.0182 - root_mean_squared_error: 0.1348 - val_loss: 0.0807 - val_mae: 0.2755 - val_mse: 0.0807 - val_root_mean_squared_error: 0.2840\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0184 - mae: 0.1179 - mse: 0.0184 - root_mean_squared_error: 0.1357 - val_loss: 0.0820 - val_mae: 0.2778 - val_mse: 0.0820 - val_root_mean_squared_error: 0.2863\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0183 - mae: 0.1164 - mse: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0832 - val_mae: 0.2800 - val_mse: 0.0832 - val_root_mean_squared_error: 0.2885\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0176 - mae: 0.1158 - mse: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0837 - val_mae: 0.2808 - val_mse: 0.0837 - val_root_mean_squared_error: 0.2892\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0179 - mae: 0.1154 - mse: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0834 - val_mae: 0.2804 - val_mse: 0.0834 - val_root_mean_squared_error: 0.2888\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0177 - mae: 0.1143 - mse: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0824 - val_mae: 0.2786 - val_mse: 0.0824 - val_root_mean_squared_error: 0.2870\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0179 - mae: 0.1138 - mse: 0.0179 - root_mean_squared_error: 0.1338 - val_loss: 0.0809 - val_mae: 0.2759 - val_mse: 0.0809 - val_root_mean_squared_error: 0.2844\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0180 - mae: 0.1154 - mse: 0.0180 - root_mean_squared_error: 0.1342 - val_loss: 0.0794 - val_mae: 0.2731 - val_mse: 0.0794 - val_root_mean_squared_error: 0.2817\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0172 - mae: 0.1137 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0779 - val_mae: 0.2703 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2791\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0175 - mae: 0.1143 - mse: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0768 - val_mae: 0.2683 - val_mse: 0.0768 - val_root_mean_squared_error: 0.2771\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0162 - mae: 0.1107 - mse: 0.0162 - root_mean_squared_error: 0.1273 - val_loss: 0.0757 - val_mae: 0.2662 - val_mse: 0.0757 - val_root_mean_squared_error: 0.2751\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0167 - mae: 0.1122 - mse: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0751 - val_mae: 0.2651 - val_mse: 0.0751 - val_root_mean_squared_error: 0.2740\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0169 - mae: 0.1125 - mse: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0748 - val_mae: 0.2645 - val_mse: 0.0748 - val_root_mean_squared_error: 0.2734\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0178 - mae: 0.1151 - mse: 0.0178 - root_mean_squared_error: 0.1333 - val_loss: 0.0753 - val_mae: 0.2655 - val_mse: 0.0753 - val_root_mean_squared_error: 0.2744\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0188 - mae: 0.1195 - mse: 0.0188 - root_mean_squared_error: 0.1369 - val_loss: 0.0771 - val_mae: 0.2688 - val_mse: 0.0771 - val_root_mean_squared_error: 0.2776\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0181 - mae: 0.1161 - mse: 0.0181 - root_mean_squared_error: 0.1347 - val_loss: 0.0793 - val_mae: 0.2730 - val_mse: 0.0793 - val_root_mean_squared_error: 0.2816\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0176 - mae: 0.1150 - mse: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0816 - val_mae: 0.2771 - val_mse: 0.0816 - val_root_mean_squared_error: 0.2857\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0174 - mae: 0.1146 - mse: 0.0174 - root_mean_squared_error: 0.1321 - val_loss: 0.0830 - val_mae: 0.2796 - val_mse: 0.0830 - val_root_mean_squared_error: 0.2881\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0183 - mae: 0.1151 - mse: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0836 - val_mae: 0.2807 - val_mse: 0.0836 - val_root_mean_squared_error: 0.2891\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0174 - mae: 0.1125 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0830 - val_mae: 0.2797 - val_mse: 0.0830 - val_root_mean_squared_error: 0.2882\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0173 - mae: 0.1135 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0815 - val_mae: 0.2770 - val_mse: 0.0815 - val_root_mean_squared_error: 0.2855\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0175 - mae: 0.1136 - mse: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0797 - val_mae: 0.2737 - val_mse: 0.0797 - val_root_mean_squared_error: 0.2823\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0176 - mae: 0.1144 - mse: 0.0176 - root_mean_squared_error: 0.1328 - val_loss: 0.0781 - val_mae: 0.2707 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2794\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0174 - mae: 0.1127 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0766 - val_mae: 0.2681 - val_mse: 0.0766 - val_root_mean_squared_error: 0.2768\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0174 - mae: 0.1141 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0758 - val_mae: 0.2666 - val_mse: 0.0758 - val_root_mean_squared_error: 0.2754\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0178 - mae: 0.1157 - mse: 0.0178 - root_mean_squared_error: 0.1332 - val_loss: 0.0760 - val_mae: 0.2668 - val_mse: 0.0760 - val_root_mean_squared_error: 0.2757\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0171 - mae: 0.1136 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0760 - val_mae: 0.2669 - val_mse: 0.0760 - val_root_mean_squared_error: 0.2757\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0181 - mae: 0.1168 - mse: 0.0181 - root_mean_squared_error: 0.1345 - val_loss: 0.0769 - val_mae: 0.2686 - val_mse: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0164 - mae: 0.1110 - mse: 0.0164 - root_mean_squared_error: 0.1282 - val_loss: 0.0775 - val_mae: 0.2696 - val_mse: 0.0775 - val_root_mean_squared_error: 0.2784\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0177 - mae: 0.1157 - mse: 0.0177 - root_mean_squared_error: 0.1332 - val_loss: 0.0786 - val_mae: 0.2716 - val_mse: 0.0786 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0172 - mae: 0.1130 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0793 - val_mae: 0.2729 - val_mse: 0.0793 - val_root_mean_squared_error: 0.2816\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0179 - mae: 0.1162 - mse: 0.0179 - root_mean_squared_error: 0.1338 - val_loss: 0.0802 - val_mae: 0.2747 - val_mse: 0.0802 - val_root_mean_squared_error: 0.2832\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0171 - mae: 0.1133 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0805 - val_mae: 0.2751 - val_mse: 0.0805 - val_root_mean_squared_error: 0.2837\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0172 - mae: 0.1133 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0803 - val_mae: 0.2747 - val_mse: 0.0803 - val_root_mean_squared_error: 0.2833\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0175 - mae: 0.1142 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0799 - val_mae: 0.2741 - val_mse: 0.0799 - val_root_mean_squared_error: 0.2827\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0174 - mae: 0.1148 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0796 - val_mae: 0.2735 - val_mse: 0.0796 - val_root_mean_squared_error: 0.2821\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0169 - mae: 0.1127 - mse: 0.0169 - root_mean_squared_error: 0.1299 - val_loss: 0.0787 - val_mae: 0.2719 - val_mse: 0.0787 - val_root_mean_squared_error: 0.2806\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0171 - mae: 0.1132 - mse: 0.0171 - root_mean_squared_error: 0.1309 - val_loss: 0.0778 - val_mae: 0.2702 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0174 - mae: 0.1141 - mse: 0.0174 - root_mean_squared_error: 0.1317 - val_loss: 0.0771 - val_mae: 0.2690 - val_mse: 0.0771 - val_root_mean_squared_error: 0.2777\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0174 - mae: 0.1147 - mse: 0.0174 - root_mean_squared_error: 0.1317 - val_loss: 0.0769 - val_mae: 0.2685 - val_mse: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0175 - mae: 0.1161 - mse: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0770 - val_mae: 0.2688 - val_mse: 0.0770 - val_root_mean_squared_error: 0.2775\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0177 - mae: 0.1152 - mse: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0775 - val_mae: 0.2697 - val_mse: 0.0775 - val_root_mean_squared_error: 0.2784\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0176 - mae: 0.1144 - mse: 0.0176 - root_mean_squared_error: 0.1326 - val_loss: 0.0785 - val_mae: 0.2715 - val_mse: 0.0785 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0172 - mae: 0.1139 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0794 - val_mae: 0.2731 - val_mse: 0.0794 - val_root_mean_squared_error: 0.2817\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0174 - mae: 0.1145 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0799 - val_mae: 0.2740 - val_mse: 0.0799 - val_root_mean_squared_error: 0.2826\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0173 - mae: 0.1141 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0798 - val_mae: 0.2738 - val_mse: 0.0798 - val_root_mean_squared_error: 0.2825\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0175 - mae: 0.1151 - mse: 0.0175 - root_mean_squared_error: 0.1325 - val_loss: 0.0797 - val_mae: 0.2737 - val_mse: 0.0797 - val_root_mean_squared_error: 0.2823\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0172 - mae: 0.1140 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0794 - val_mae: 0.2732 - val_mse: 0.0794 - val_root_mean_squared_error: 0.2818\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0178 - mae: 0.1155 - mse: 0.0178 - root_mean_squared_error: 0.1335 - val_loss: 0.0793 - val_mae: 0.2729 - val_mse: 0.0793 - val_root_mean_squared_error: 0.2815\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0172 - mae: 0.1145 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0788 - val_mae: 0.2720 - val_mse: 0.0788 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0177 - mae: 0.1163 - mse: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0789 - val_mae: 0.2722 - val_mse: 0.0789 - val_root_mean_squared_error: 0.2809\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0170 - mae: 0.1132 - mse: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0787 - val_mae: 0.2719 - val_mse: 0.0787 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0171 - mae: 0.1131 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0784 - val_mae: 0.2713 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0173 - mae: 0.1137 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0782 - val_mae: 0.2710 - val_mse: 0.0782 - val_root_mean_squared_error: 0.2797\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0172 - mae: 0.1141 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0781 - val_mae: 0.2708 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0170 - mae: 0.1134 - mse: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0781 - val_mae: 0.2707 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0176 - mae: 0.1144 - mse: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0785 - val_mae: 0.2714 - val_mse: 0.0785 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0173 - mae: 0.1136 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0783 - val_mae: 0.2711 - val_mse: 0.0783 - val_root_mean_squared_error: 0.2798\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0173 - mae: 0.1142 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0780 - val_mae: 0.2706 - val_mse: 0.0780 - val_root_mean_squared_error: 0.2793\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0176 - mae: 0.1151 - mse: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0785 - val_mae: 0.2715 - val_mse: 0.0785 - val_root_mean_squared_error: 0.2802\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0172 - mae: 0.1134 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0789 - val_mae: 0.2722 - val_mse: 0.0789 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0173 - mae: 0.1139 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0791 - val_mae: 0.2725 - val_mse: 0.0791 - val_root_mean_squared_error: 0.2812\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0170 - mae: 0.1126 - mse: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0788 - val_mae: 0.2720 - val_mse: 0.0788 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0172 - mae: 0.1141 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0784 - val_mae: 0.2713 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0173 - mae: 0.1144 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0778 - val_mae: 0.2703 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0171 - mae: 0.1137 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0772 - val_mae: 0.2691 - val_mse: 0.0772 - val_root_mean_squared_error: 0.2778\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0171 - mae: 0.1146 - mse: 0.0171 - root_mean_squared_error: 0.1310 - val_loss: 0.0770 - val_mae: 0.2687 - val_mse: 0.0770 - val_root_mean_squared_error: 0.2775\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0169 - mae: 0.1136 - mse: 0.0169 - root_mean_squared_error: 0.1301 - val_loss: 0.0768 - val_mae: 0.2684 - val_mse: 0.0768 - val_root_mean_squared_error: 0.2772\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0176 - mae: 0.1144 - mse: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0776 - val_mae: 0.2699 - val_mse: 0.0776 - val_root_mean_squared_error: 0.2786\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0173 - mae: 0.1134 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0786 - val_mae: 0.2717 - val_mse: 0.0786 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0180 - mae: 0.1170 - mse: 0.0180 - root_mean_squared_error: 0.1342 - val_loss: 0.0806 - val_mae: 0.2753 - val_mse: 0.0806 - val_root_mean_squared_error: 0.2838\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0177 - mae: 0.1153 - mse: 0.0177 - root_mean_squared_error: 0.1330 - val_loss: 0.0823 - val_mae: 0.2783 - val_mse: 0.0823 - val_root_mean_squared_error: 0.2868\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0178 - mae: 0.1156 - mse: 0.0178 - root_mean_squared_error: 0.1336 - val_loss: 0.0833 - val_mae: 0.2802 - val_mse: 0.0833 - val_root_mean_squared_error: 0.2886\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.0175 - mae: 0.1144 - mse: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0829 - val_mae: 0.2795 - val_mse: 0.0829 - val_root_mean_squared_error: 0.2879\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0174 - mae: 0.1139 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0812 - val_mae: 0.2763 - val_mse: 0.0812 - val_root_mean_squared_error: 0.2849\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0175 - mae: 0.1152 - mse: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0787 - val_mae: 0.2719 - val_mse: 0.0787 - val_root_mean_squared_error: 0.2806\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0173 - mae: 0.1139 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0765 - val_mae: 0.2678 - val_mse: 0.0765 - val_root_mean_squared_error: 0.2766\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0176 - mae: 0.1155 - mse: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0754 - val_mae: 0.2657 - val_mse: 0.0754 - val_root_mean_squared_error: 0.2746\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0172 - mae: 0.1143 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0756 - val_mae: 0.2660 - val_mse: 0.0756 - val_root_mean_squared_error: 0.2749\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0174 - mae: 0.1143 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0769 - val_mae: 0.2685 - val_mse: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0172 - mae: 0.1131 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0786 - val_mae: 0.2716 - val_mse: 0.0786 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.0174 - mae: 0.1144 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0802 - val_mae: 0.2746 - val_mse: 0.0802 - val_root_mean_squared_error: 0.2832\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0175 - mae: 0.1150 - mse: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0816 - val_mae: 0.2771 - val_mse: 0.0816 - val_root_mean_squared_error: 0.2857\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0173 - mae: 0.1143 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0816 - val_mae: 0.2771 - val_mse: 0.0816 - val_root_mean_squared_error: 0.2856\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0172 - mae: 0.1139 - mse: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0801 - val_mae: 0.2744 - val_mse: 0.0801 - val_root_mean_squared_error: 0.2830\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0174 - mae: 0.1137 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0783 - val_mae: 0.2712 - val_mse: 0.0783 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0173 - mae: 0.1142 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0768 - val_mae: 0.2684 - val_mse: 0.0768 - val_root_mean_squared_error: 0.2771\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0175 - mae: 0.1148 - mse: 0.0175 - root_mean_squared_error: 0.1321 - val_loss: 0.0761 - val_mae: 0.2671 - val_mse: 0.0761 - val_root_mean_squared_error: 0.2759\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0171 - mae: 0.1137 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0761 - val_mae: 0.2670 - val_mse: 0.0761 - val_root_mean_squared_error: 0.2758\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0171 - mae: 0.1139 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0764 - val_mae: 0.2676 - val_mse: 0.0764 - val_root_mean_squared_error: 0.2764\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0172 - mae: 0.1138 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0770 - val_mae: 0.2688 - val_mse: 0.0770 - val_root_mean_squared_error: 0.2776\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0172 - mae: 0.1139 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0778 - val_mae: 0.2701 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2789\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0175 - mae: 0.1154 - mse: 0.0175 - root_mean_squared_error: 0.1324 - val_loss: 0.0794 - val_mae: 0.2731 - val_mse: 0.0794 - val_root_mean_squared_error: 0.2817\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0174 - mae: 0.1143 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0804 - val_mae: 0.2750 - val_mse: 0.0804 - val_root_mean_squared_error: 0.2836\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0174 - mae: 0.1145 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0811 - val_mae: 0.2762 - val_mse: 0.0811 - val_root_mean_squared_error: 0.2847\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0173 - mae: 0.1138 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0803 - val_mae: 0.2748 - val_mse: 0.0803 - val_root_mean_squared_error: 0.2834\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0174 - mae: 0.1146 - mse: 0.0174 - root_mean_squared_error: 0.1321 - val_loss: 0.0792 - val_mae: 0.2728 - val_mse: 0.0792 - val_root_mean_squared_error: 0.2814\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.0172 - mae: 0.1145 - mse: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0781 - val_mae: 0.2707 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2794\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0176 - mae: 0.1157 - mse: 0.0176 - root_mean_squared_error: 0.1328 - val_loss: 0.0777 - val_mae: 0.2700 - val_mse: 0.0777 - val_root_mean_squared_error: 0.2787\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0174 - mae: 0.1153 - mse: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0778 - val_mae: 0.2702 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0170 - mae: 0.1136 - mse: 0.0170 - root_mean_squared_error: 0.1303 - val_loss: 0.0779 - val_mae: 0.2703 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2791\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0172 - mae: 0.1141 - mse: 0.0172 - root_mean_squared_error: 0.1310 - val_loss: 0.0775 - val_mae: 0.2696 - val_mse: 0.0775 - val_root_mean_squared_error: 0.2783\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0171 - mae: 0.1137 - mse: 0.0171 - root_mean_squared_error: 0.1306 - val_loss: 0.0770 - val_mae: 0.2687 - val_mse: 0.0770 - val_root_mean_squared_error: 0.2775\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0173 - mae: 0.1148 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0774 - val_mae: 0.2695 - val_mse: 0.0774 - val_root_mean_squared_error: 0.2783\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0171 - mae: 0.1141 - mse: 0.0171 - root_mean_squared_error: 0.1306 - val_loss: 0.0778 - val_mae: 0.2702 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0173 - mae: 0.1153 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0789 - val_mae: 0.2722 - val_mse: 0.0789 - val_root_mean_squared_error: 0.2808\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0173 - mae: 0.1141 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0799 - val_mae: 0.2740 - val_mse: 0.0799 - val_root_mean_squared_error: 0.2826\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0173 - mae: 0.1144 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0805 - val_mae: 0.2751 - val_mse: 0.0805 - val_root_mean_squared_error: 0.2837\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0174 - mae: 0.1145 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0809 - val_mae: 0.2758 - val_mse: 0.0809 - val_root_mean_squared_error: 0.2844\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0175 - mae: 0.1145 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0812 - val_mae: 0.2764 - val_mse: 0.0812 - val_root_mean_squared_error: 0.2850\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0174 - mae: 0.1142 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0807 - val_mae: 0.2755 - val_mse: 0.0807 - val_root_mean_squared_error: 0.2840\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0172 - mae: 0.1137 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0791 - val_mae: 0.2726 - val_mse: 0.0791 - val_root_mean_squared_error: 0.2812\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0176 - mae: 0.1149 - mse: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0784 - val_mae: 0.2714 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2801\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0173 - mae: 0.1146 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0779 - val_mae: 0.2704 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2791\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0173 - mae: 0.1143 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0778 - val_mae: 0.2702 - val_mse: 0.0778 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0170 - mae: 0.1133 - mse: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0771 - val_mae: 0.2690 - val_mse: 0.0771 - val_root_mean_squared_error: 0.2778\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0175 - mae: 0.1153 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0777 - val_mae: 0.2700 - val_mse: 0.0777 - val_root_mean_squared_error: 0.2787\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0173 - mae: 0.1150 - mse: 0.0173 - root_mean_squared_error: 0.1315 - val_loss: 0.0782 - val_mae: 0.2710 - val_mse: 0.0782 - val_root_mean_squared_error: 0.2797\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0173 - mae: 0.1144 - mse: 0.0173 - root_mean_squared_error: 0.1314 - val_loss: 0.0788 - val_mae: 0.2720 - val_mse: 0.0788 - val_root_mean_squared_error: 0.2806\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0171 - mae: 0.1138 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0786 - val_mae: 0.2716 - val_mse: 0.0786 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0174 - mae: 0.1148 - mse: 0.0174 - root_mean_squared_error: 0.1318 - val_loss: 0.0784 - val_mae: 0.2712 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2799\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0174 - mae: 0.1143 - mse: 0.0174 - root_mean_squared_error: 0.1320 - val_loss: 0.0787 - val_mae: 0.2718 - val_mse: 0.0787 - val_root_mean_squared_error: 0.2804\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0172 - mae: 0.1144 - mse: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0788 - val_mae: 0.2721 - val_mse: 0.0788 - val_root_mean_squared_error: 0.2807\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0172 - mae: 0.1135 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0787 - val_mae: 0.2718 - val_mse: 0.0787 - val_root_mean_squared_error: 0.2805\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0170 - mae: 0.1138 - mse: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0779 - val_mae: 0.2704 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2791\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0173 - mae: 0.1145 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0773 - val_mae: 0.2693 - val_mse: 0.0773 - val_root_mean_squared_error: 0.2780\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0171 - mae: 0.1142 - mse: 0.0171 - root_mean_squared_error: 0.1309 - val_loss: 0.0770 - val_mae: 0.2688 - val_mse: 0.0770 - val_root_mean_squared_error: 0.2776\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0169 - mae: 0.1128 - mse: 0.0169 - root_mean_squared_error: 0.1302 - val_loss: 0.0766 - val_mae: 0.2681 - val_mse: 0.0766 - val_root_mean_squared_error: 0.2769\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0171 - mae: 0.1133 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0760 - val_mae: 0.2668 - val_mse: 0.0760 - val_root_mean_squared_error: 0.2756\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0170 - mae: 0.1138 - mse: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0755 - val_mae: 0.2660 - val_mse: 0.0755 - val_root_mean_squared_error: 0.2748\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0173 - mae: 0.1149 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0762 - val_mae: 0.2673 - val_mse: 0.0762 - val_root_mean_squared_error: 0.2761\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0173 - mae: 0.1149 - mse: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0779 - val_mae: 0.2703 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2790\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0175 - mae: 0.1154 - mse: 0.0175 - root_mean_squared_error: 0.1321 - val_loss: 0.0801 - val_mae: 0.2743 - val_mse: 0.0801 - val_root_mean_squared_error: 0.2829\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0172 - mae: 0.1140 - mse: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0815 - val_mae: 0.2769 - val_mse: 0.0815 - val_root_mean_squared_error: 0.2854\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0173 - mae: 0.1143 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0819 - val_mae: 0.2776 - val_mse: 0.0819 - val_root_mean_squared_error: 0.2861\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0171 - mae: 0.1133 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0796 - val_mae: 0.2736 - val_mse: 0.0796 - val_root_mean_squared_error: 0.2822\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0171 - mae: 0.1140 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0766 - val_mae: 0.2679 - val_mse: 0.0766 - val_root_mean_squared_error: 0.2767\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0172 - mae: 0.1142 - mse: 0.0172 - root_mean_squared_error: 0.1311 - val_loss: 0.0741 - val_mae: 0.2633 - val_mse: 0.0741 - val_root_mean_squared_error: 0.2723\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0174 - mae: 0.1152 - mse: 0.0174 - root_mean_squared_error: 0.1319 - val_loss: 0.0739 - val_mae: 0.2629 - val_mse: 0.0739 - val_root_mean_squared_error: 0.2718\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0173 - mae: 0.1148 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0757 - val_mae: 0.2663 - val_mse: 0.0757 - val_root_mean_squared_error: 0.2751\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0171 - mae: 0.1138 - mse: 0.0171 - root_mean_squared_error: 0.1308 - val_loss: 0.0781 - val_mae: 0.2708 - val_mse: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0169 - mae: 0.1136 - mse: 0.0169 - root_mean_squared_error: 0.1300 - val_loss: 0.0796 - val_mae: 0.2735 - val_mse: 0.0796 - val_root_mean_squared_error: 0.2821\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0171 - mae: 0.1141 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0795 - val_mae: 0.2733 - val_mse: 0.0795 - val_root_mean_squared_error: 0.2819\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0172 - mae: 0.1141 - mse: 0.0172 - root_mean_squared_error: 0.1312 - val_loss: 0.0784 - val_mae: 0.2714 - val_mse: 0.0784 - val_root_mean_squared_error: 0.2800\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0171 - mae: 0.1135 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0769 - val_mae: 0.2685 - val_mse: 0.0769 - val_root_mean_squared_error: 0.2773\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0172 - mae: 0.1145 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0758 - val_mae: 0.2665 - val_mse: 0.0758 - val_root_mean_squared_error: 0.2754\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0171 - mae: 0.1140 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0757 - val_mae: 0.2663 - val_mse: 0.0757 - val_root_mean_squared_error: 0.2751\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0173 - mae: 0.1150 - mse: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0772 - val_mae: 0.2691 - val_mse: 0.0772 - val_root_mean_squared_error: 0.2778\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0175 - mae: 0.1153 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0799 - val_mae: 0.2741 - val_mse: 0.0799 - val_root_mean_squared_error: 0.2827\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0170 - mae: 0.1137 - mse: 0.0170 - root_mean_squared_error: 0.1305 - val_loss: 0.0807 - val_mae: 0.2755 - val_mse: 0.0807 - val_root_mean_squared_error: 0.2840\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0175 - mae: 0.1150 - mse: 0.0175 - root_mean_squared_error: 0.1322 - val_loss: 0.0813 - val_mae: 0.2765 - val_mse: 0.0813 - val_root_mean_squared_error: 0.2851\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0174 - mae: 0.1143 - mse: 0.0174 - root_mean_squared_error: 0.1317 - val_loss: 0.0803 - val_mae: 0.2748 - val_mse: 0.0803 - val_root_mean_squared_error: 0.2834\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0171 - mae: 0.1133 - mse: 0.0171 - root_mean_squared_error: 0.1307 - val_loss: 0.0779 - val_mae: 0.2704 - val_mse: 0.0779 - val_root_mean_squared_error: 0.2791\n"
     ]
    }
   ],
   "source": [
    "# Train the keras model\n",
    "history_keras = keras_model.fit(train_data_inputs, train_data_targets,\n",
    "          validation_data=(val_data_inputs, val_data_targets),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1368x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history, model_name, ax):\n",
    "    ax.plot(history.history['loss'], label='Training Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training and Validation Loss for ' + model_name)\n",
    "    ax.legend()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(19, 8))\n",
    "\n",
    "histories = [history_manual, history_keras]\n",
    "model_names = ['Manual Transformer', 'Keras Transformer']\n",
    "\n",
    "for history, model_name, ax in zip(histories, model_names, axes):\n",
    "    plot_loss(history, model_name, ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0063 - mae: 0.0626 - mse: 0.0063 - root_mean_squared_error: 0.0796\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0779 - mae: 0.2704 - mse: 0.0779 - root_mean_squared_error: 0.2791\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1803 - mae: 0.4112 - mse: 0.1803 - root_mean_squared_error: 0.4246\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3760 - mae: 0.6085 - mse: 0.3760 - root_mean_squared_error: 0.6132\n",
      "\n",
      "\n",
      "Manual Transformer:\n",
      "-------------------\n",
      "Validation Loss: 0.006341175176203251, Validation MSE: 0.006341175176203251, Validation MAE: 0.06263889372348785, Validation RMSE: 0.0796314999461174\n",
      "Test Loss: 0.1802843064069748, Test MSE: 0.1802843064069748, Test MAE: 0.41124460101127625, Test RMSE: 0.4245989918708801\n",
      "\n",
      "Keras Transformer:\n",
      "------------------\n",
      "Validation Loss: 0.07791902124881744, Validation MSE: 0.07791902124881744, Validation MAE: 0.27042001485824585, Validation RMSE: 0.27913978695869446\n",
      "Test Loss: 0.3759670555591583, Test MSE: 0.3759670555591583, Test MAE: 0.6084648966789246, Test RMSE: 0.6131615042686462\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_metrics_manual = manual_model.evaluate(val_data_inputs, val_data_targets, return_dict=True)\n",
    "val_metrics_keras = keras_model.evaluate(val_data_inputs, val_data_targets, return_dict=True)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics_manual = manual_model.evaluate(test_data_inputs, test_data_targets, return_dict=True)\n",
    "test_metrics_keras = keras_model.evaluate(test_data_inputs, test_data_targets, return_dict=True)\n",
    "\n",
    "# Extract individual metrics\n",
    "val_loss_manual, val_mae_manual, val_mse_manual, val_rmse_manual = val_metrics_manual['loss'], val_metrics_manual['mae'], val_metrics_manual['mse'], val_metrics_manual['root_mean_squared_error']\n",
    "test_loss_manual, test_mae_manual, test_mse_manual, test_rmse_manual = test_metrics_manual['loss'], test_metrics_manual['mae'], test_metrics_manual['mse'], test_metrics_manual['root_mean_squared_error']\n",
    "\n",
    "val_loss_keras, val_mae_keras, val_mse_keras, val_rmse_keras = val_metrics_keras['loss'], val_metrics_keras['mae'], val_metrics_keras['mse'], val_metrics_keras['root_mean_squared_error']\n",
    "test_loss_keras, test_mae_keras, test_mse_keras, test_rmse_keras = test_metrics_keras['loss'], test_metrics_keras['mae'], test_metrics_keras['mse'], test_metrics_keras['root_mean_squared_error']\n",
    "\n",
    "print('\\n\\nManual Transformer:\\n-------------------')\n",
    "print(f'Validation Loss: {val_loss_manual}, Validation MSE: {val_mse_manual}, Validation MAE: {val_mae_manual}, Validation RMSE: {val_rmse_manual}')\n",
    "print(f'Test Loss: {test_loss_manual}, Test MSE: {test_mse_manual}, Test MAE: {test_mae_manual}, Test RMSE: {test_rmse_manual}')\n",
    "\n",
    "print('\\nKeras Transformer:\\n------------------')\n",
    "print(f'Validation Loss: {val_loss_keras}, Validation MSE: {val_mse_keras}, Validation MAE: {val_mae_keras}, Validation RMSE: {val_rmse_keras}')\n",
    "print(f'Test Loss: {test_loss_keras}, Test MSE: {test_mse_keras}, Test MAE: {test_mae_keras}, Test RMSE: {test_rmse_keras}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "\n",
      "\n",
      "Manual Transformer:\n",
      "-------------------\n",
      "Validation MAE: 0.07047449797391891\n",
      "Validation RMSE: 0.0884234681725502\n",
      "\n",
      "Test MAE: 0.4112445881951989\n",
      "Test RMSE: 0.4202875239154641\n",
      "\n",
      "==============================\n",
      "\n",
      "Keras Transformer:\n",
      "------------------\n",
      "Validation MAE: 0.27041998505592346\n",
      "Validation RMSE: 0.27913978695869446\n",
      "\n",
      "Test MAE: 0.6084649051502203\n",
      "Test RMSE: 0.6131615307704102\n"
     ]
    }
   ],
   "source": [
    "# Assuming manual_model.predict returns the predictions\n",
    "val_predictions_manual = manual_model.predict(val_data_inputs)\n",
    "test_predictions_manual = manual_model.predict(test_data_inputs)\n",
    "\n",
    "# Assuming keras_model.predict returns the predictions\n",
    "val_predictions_keras = keras_model.predict(val_data_inputs)\n",
    "test_predictions_keras  = keras_model.predict(test_data_inputs)\n",
    "\n",
    "# Calculate MAE and RMSE for validation set\n",
    "val_mae_manual = np.mean(np.abs(val_data_targets - val_predictions_manual))\n",
    "val_rmse_manual = np.sqrt(np.mean(np.square(val_data_targets - val_predictions_manual)))\n",
    "\n",
    "val_mae_keras  = np.mean(np.abs(val_data_targets - val_predictions_keras ))\n",
    "val_rmse_keras  = np.sqrt(np.mean(np.square(val_data_targets - val_predictions_keras )))\n",
    "\n",
    "# Calculate MAE and RMSE for test set\n",
    "test_mae_manual = np.mean(np.abs(test_data_targets - test_predictions_manual))\n",
    "test_rmse_manual = np.sqrt(np.mean(np.square(test_data_targets - test_predictions_manual)))\n",
    "\n",
    "test_mae_keras  = np.mean(np.abs(test_data_targets - test_predictions_keras ))\n",
    "test_rmse_keras  = np.sqrt(np.mean(np.square(test_data_targets - test_predictions_keras )))\n",
    "\n",
    "\n",
    "print('\\n\\nManual Transformer:\\n-------------------')\n",
    "print(f'Validation MAE: {val_mae_manual}')\n",
    "print(f'Validation RMSE: {val_rmse_manual}')\n",
    "print(f'\\nTest MAE: {test_mae_manual}')\n",
    "print(f'Test RMSE: {test_rmse_manual}')\n",
    "print('\\n==============================')\n",
    "print('\\nKeras Transformer:\\n------------------')\n",
    "print(f'Validation MAE: {val_mae_keras }')\n",
    "print(f'Validation RMSE: {val_rmse_keras }')\n",
    "print(f'\\nTest MAE: {test_mae_keras }')\n",
    "print(f'Test RMSE: {test_rmse_keras }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "\n",
      "\n",
      "Evaluation metrics for Keras Transformer model:\n",
      "-------------------\n",
      "Train Dataset:\n",
      "RMSE: 130.40876924309197\n",
      "MAE: 101.88476235247882\n",
      "-------------------\n",
      "Validation Dataset:\n",
      "RMSE: 314.7856732234422\n",
      "Validation MAE: 247.61339965018732\n",
      "-------------------\n",
      "Test Dataset:\n",
      "Test RMSE: 1678.4525914680878\n",
      "Test MAE: 1625.6621944732667\n",
      "\n",
      "\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "\n",
      "Evaluation metrics for Keras Transformer model:\n",
      "-------------------\n",
      "Train Dataset:\n",
      "RMSE: 518.6019838163944\n",
      "MAE: 451.4432205732321\n",
      "-------------------\n",
      "Validation Dataset:\n",
      "RMSE: 1103.4478935040145\n",
      "Validation MAE: 1068.9783338375955\n",
      "-------------------\n",
      "Test Dataset:\n",
      "Test RMSE: 2423.845931470756\n",
      "Test MAE: 2405.2800240059746\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions_model(model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler):\n",
    "    # Predictions on training data\n",
    "    y_pred_train = model.predict(train_data_inputs)\n",
    "    inversed_y_pred_train = scaler.inverse_transform(np.concatenate([y_pred_train, np.zeros((y_pred_train.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_train = inversed_y_pred_train[:, 0]\n",
    "\n",
    "    # Inverse the target train data\n",
    "    train_targets_scaled_data = train_data_targets.reshape(-1,1)\n",
    "    train_targets_data = scaler.inverse_transform(np.concatenate([train_targets_scaled_data, np.zeros((train_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    train_targets_data = train_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on training data\n",
    "    train_rmse = calculate_rmse(train_targets_data, inversed_y_pred_train)\n",
    "    train_mae = calculate_mae(train_targets_data, inversed_y_pred_train)\n",
    "\n",
    "    # Predictions on validation data\n",
    "    y_pred_val = model.predict(val_data_inputs)\n",
    "    inversed_y_pred_val = scaler.inverse_transform(np.concatenate([y_pred_val, np.zeros((y_pred_val.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_val = inversed_y_pred_val[:, 0]\n",
    "    \n",
    "    # Inverse the target validation data\n",
    "    val_targets_scaled_data = val_data_targets.reshape(-1,1)\n",
    "    val_targets_data = scaler.inverse_transform(np.concatenate([val_targets_scaled_data, np.zeros((val_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    val_targets_data = val_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on validation data\n",
    "    val_rmse = calculate_rmse(val_targets_data, inversed_y_pred_val)\n",
    "    val_mae = calculate_mae(val_targets_data, inversed_y_pred_val)\n",
    "\n",
    "    # Predictions on test data\n",
    "    y_pred_test = model.predict(test_data_inputs)\n",
    "    inversed_y_pred_test = scaler.inverse_transform(np.concatenate([y_pred_test, np.zeros((y_pred_test.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_test = inversed_y_pred_test[:, 0]\n",
    "\n",
    "    test_targets_scaled_data = test_data_targets.reshape(-1,1)\n",
    "    test_targets_data = scaler.inverse_transform(np.concatenate([test_targets_scaled_data, np.zeros((test_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    test_targets_data = test_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on test data\n",
    "    test_rmse = calculate_rmse(test_targets_data, inversed_y_pred_test)\n",
    "    test_mae = calculate_mae(test_targets_data, inversed_y_pred_test)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\n\\nEvaluation metrics for {model_name} model:\\n-------------------\")\n",
    "    print('Train Dataset:')\n",
    "    print(f\"RMSE: {train_rmse}\")\n",
    "    print(f\"MAE: {train_mae}\\n-------------------\")\n",
    "\n",
    "    print('Validation Dataset:')\n",
    "    print(f\"RMSE: {val_rmse}\")\n",
    "    print(f\"Validation MAE: {val_mae}\\n-------------------\")\n",
    "    \n",
    "    print('Test Dataset:')\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "    print(f\"Test MAE: {test_mae}\\n\\n\")\n",
    "\n",
    "evaluate_predictions_model(manual_model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler)\n",
    "evaluate_predictions_model(keras_model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
