{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1668 entries, 0 to 1667\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Energy__kWh_   1668 non-null   float64\n",
      " 1   Weekday        1668 non-null   object \n",
      " 2   Month          1668 non-null   object \n",
      " 3   Minimum T      1668 non-null   int64  \n",
      " 4   Maximum T      1668 non-null   int64  \n",
      " 5   Snow           1668 non-null   float64\n",
      " 6   Precipitation  1668 non-null   float64\n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 91.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from Transformer import *\n",
    "\n",
    "# Import the utils from the Time2Vec Transformer\n",
    "import sys\n",
    "sys.path.append(\"../Time2Vec\")\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "daily = pd.read_csv('../../../Dataset/Boulder_Daily.csv')\n",
    "daily.drop(columns={'Unnamed: 0'}, inplace=True)\n",
    "daily.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Scale the Dataset with MinMaxScaler / One-Hot Encode and Extract the Entire Scaled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy__kWh_', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation',\n",
       "       'Weekday_Friday', 'Weekday_Monday', 'Weekday_Saturday',\n",
       "       'Weekday_Sunday', 'Weekday_Thursday', 'Weekday_Tuesday',\n",
       "       'Weekday_Wednesday', 'Month_April', 'Month_August', 'Month_December',\n",
       "       'Month_February', 'Month_January', 'Month_July', 'Month_June',\n",
       "       'Month_March', 'Month_May', 'Month_November', 'Month_October',\n",
       "       'Month_September'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns we need to scale and we need to use for One-Hot Encoding\n",
    "columns_to_scale = ['Energy__kWh_', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation']\n",
    "categorical_columns = ['Weekday','Month']\n",
    "\n",
    "# MinMax scaling for numerical columns and One-hot encoding for categorical columns\n",
    "scaler = MinMaxScaler()\n",
    "daily_scaled = daily.copy()\n",
    "daily_scaled[columns_to_scale] = scaler.fit_transform(daily[columns_to_scale])\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "categorical_encoded = onehot_encoder.fit_transform(daily[categorical_columns])\n",
    "\n",
    "# Get the feature names from the encoder\n",
    "encoded_columns = []\n",
    "for col, values in zip(categorical_columns, onehot_encoder.categories_):\n",
    "    encoded_columns.extend([f'{col}_{value}' for value in values])\n",
    "\n",
    "# Create DataFrame with encoded columns\n",
    "categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=encoded_columns)\n",
    "\n",
    "# Concatenate the new encoded columns to the original DataFrame\n",
    "daily_scaled = pd.concat([daily_scaled, categorical_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "daily_scaled = daily_scaled.drop(categorical_columns, axis=1)\n",
    "daily_scaled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Divided the dataset into training, testing, and validation datasets according to 0.70, 0.20, and 0.10, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split ratio:   0.7\n",
      "Validation split ratio: 0.2\n",
      "Testing split ratio:    0.101\n",
      "\n",
      "Shapes of the datasets:\n",
      "(1167, 24) (333, 24) (168, 24)\n"
     ]
    }
   ],
   "source": [
    "train_daily_scaled, val_daily_scaled, test_daily_scaled = split_dataset(daily_scaled, train_ratio=0.7, val_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create sequences for the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into sequences:\n",
      "Sequences shape: (1047, 120, 24)\n",
      "Targets shape: (1047,)\n",
      "\n",
      "Dataset split into sequences:\n",
      "Sequences shape: (213, 120, 24)\n",
      "Targets shape: (213,)\n",
      "\n",
      "Dataset split into sequences:\n",
      "Sequences shape: (48, 120, 24)\n",
      "Targets shape: (48,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 120\n",
    "num_features = len(daily_scaled.columns)\n",
    "\n",
    "# Create the training, validation, and test data sequences\n",
    "train_data_inputs, train_data_targets = create_sequences(train_daily_scaled, sequence_length)\n",
    "val_data_inputs, val_data_targets = create_sequences(val_daily_scaled, sequence_length)\n",
    "test_data_inputs, test_data_targets = create_sequences(test_daily_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create the Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 120, 24)]    0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, None, 24)    2400        ['input_1[0][0]',                \n",
      " eadAttention)                                                    'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, None, 24)     0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 120, 24)     0           ['input_1[0][0]',                \n",
      " ambda)                                                           'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 120, 24)     48          ['tf.__operators__.add_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " positionwise_feed_forward_5 (P  (None, 120, 24)     3160        ['layer_normalization_10[0][0]'] \n",
      " ositionwiseFeedForward)                                                                          \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 120, 24)      0           ['positionwise_feed_forward_5[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 120, 24)     0           ['layer_normalization_10[0][0]', \n",
      " ambda)                                                           'dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 120, 24)     48          ['tf.__operators__.add_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, None, 24)    2400        ['layer_normalization_11[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_11[0][0]', \n",
      "                                                                  'layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, None, 24)     0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 120, 24)     0           ['dropout_38[0][0]',             \n",
      " ambda)                                                           'layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 120, 24)     48          ['tf.__operators__.add_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, None, 24)    2400        ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, None, 24)     0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 120, 24)     0           ['layer_normalization_27[0][0]', \n",
      " ambda)                                                           'dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 120, 24)     48          ['tf.__operators__.add_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " positionwise_feed_forward_11 (  (None, 120, 24)     3160        ['layer_normalization_28[0][0]'] \n",
      " PositionwiseFeedForward)                                                                         \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 120, 24)      0           ['positionwise_feed_forward_11[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 120, 24)     0           ['layer_normalization_28[0][0]', \n",
      " ambda)                                                           'dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 120, 24)     48          ['tf.__operators__.add_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 120)         0           ['layer_normalization_29[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 120)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 1)            121         ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,881\n",
      "Trainable params: 13,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters of the manual model\n",
    "num_heads = 1\n",
    "d_ff = 64\n",
    "num_layers = 6\n",
    "dropout_rate = 0.1\n",
    "encoder_mask = None\n",
    "decoder_mask = tf.linalg.band_part(tf.ones((sequence_length, sequence_length)), -1, 0)  # Create a lower triangular mask\n",
    "decoder_mask = 1 - decoder_mask  # Invert the mask\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   manual_model = main(sequence_length, num_features, num_heads, d_ff, num_layers, dropout_rate, encoder_mask, decoder_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 120, 24)]    0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 120, 24)     11904       ['input_2[0][0]',                \n",
      " HeadAttention)                                                   'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 120, 24)      0           ['multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 120, 24)     48          ['dropout_43[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 120, 120)     9400        ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 120, 120)     0           ['sequential_12[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 120, 120)    240         ['dropout_44[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 120, 120)    58080       ['layer_normalization_31[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 120, 120)    240         ['dropout_45[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 120, 120)     0           ['sequential_13[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 120, 120)    240         ['dropout_46[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 120, 120)    58080       ['layer_normalization_33[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 120, 120)    240         ['dropout_47[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 120, 120)     0           ['sequential_14[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 120, 120)    240         ['dropout_48[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 120, 120)    58080       ['layer_normalization_35[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 120, 120)    240         ['dropout_49[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 120, 120)     0           ['sequential_15[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 120, 120)    240         ['dropout_50[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 120, 120)    58080       ['layer_normalization_37[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_22[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 120, 120)    240         ['dropout_51[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 120, 120)     0           ['sequential_16[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 120, 120)    240         ['dropout_52[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 120, 120)    58080       ['layer_normalization_39[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_23[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 120, 120)    240         ['dropout_53[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 120, 120)     0           ['sequential_17[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 120, 120)    240         ['dropout_54[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 120, 120)    58080       ['layer_normalization_41[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_24[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 120, 120)    240         ['dropout_55[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 120, 120)    58080       ['layer_normalization_42[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 120, 120)    240         ['dropout_56[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 120, 120)     0           ['sequential_18[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 120, 120)    240         ['dropout_57[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 120, 120)    58080       ['layer_normalization_44[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 120, 120)    240         ['dropout_58[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 120, 120)    58080       ['layer_normalization_45[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 120, 120)    240         ['dropout_59[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 120, 120)     0           ['sequential_19[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 120, 120)    240         ['dropout_60[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 120, 120)    58080       ['layer_normalization_47[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_28[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 120, 120)    240         ['dropout_61[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 120, 120)    58080       ['layer_normalization_48[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 120, 120)    240         ['dropout_62[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 120, 120)     0           ['sequential_20[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 120, 120)    240         ['dropout_63[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 120, 120)    58080       ['layer_normalization_50[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_30[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 120, 120)    240         ['dropout_64[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 120, 120)    58080       ['layer_normalization_51[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_31[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 120, 120)    240         ['dropout_65[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 120, 120)     0           ['sequential_21[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 120, 120)    240         ['dropout_66[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 120, 120)    58080       ['layer_normalization_53[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 120, 120)    240         ['dropout_67[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 120, 120)    58080       ['layer_normalization_54[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 120, 120)    240         ['dropout_68[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_22 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 120, 120)     0           ['sequential_22[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 120, 120)    240         ['dropout_69[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 120, 120)    58080       ['layer_normalization_56[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_34[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 120, 120)    240         ['dropout_70[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 120, 120)    58080       ['layer_normalization_57[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 120, 120)     0           ['multi_head_attention_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 120, 120)    240         ['dropout_71[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_23 (Sequential)     (None, 120, 120)     15544       ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 120, 120)     0           ['sequential_23[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 120, 120)    240         ['dropout_72[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 120)         0           ['layer_normalization_59[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 120)          0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_121 (Dense)              (None, 1)            121         ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,186,777\n",
      "Trainable params: 1,186,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the transformer model\n",
    "input_shape = (sequence_length, num_features)\n",
    "keras_model = keras_transformer_model(input_shape, num_heads, d_ff, num_layers, dropout_rate)\n",
    "\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compile the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate for Adam optimizer\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Compile the manual model\n",
    "manual_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse',  metrics=['mae', 'mse', root_mean_squared_error])\n",
    "\n",
    "# Compile the keras model\n",
    "keras_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse',  metrics=['mae', 'mse', root_mean_squared_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1047, 120, 24), (1047,), (213, 120, 24), (213,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters for training\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "\n",
    "# Convert the data to float32\n",
    "train_data_inputs = train_data_inputs.astype('float32')\n",
    "train_data_targets = train_data_targets.astype('float32')\n",
    "\n",
    "val_data_inputs = val_data_inputs.astype('float32')\n",
    "val_data_targets = val_data_targets.astype('float32')\n",
    "\n",
    "train_data_inputs.shape, train_data_targets.shape, val_data_inputs.shape, val_data_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "33/33 [==============================] - 9s 115ms/step - loss: 3.3347 - mae: 1.2375 - mse: 3.3347 - root_mean_squared_error: 1.2617 - val_loss: 2.0287 - val_mae: 1.4200 - val_mse: 2.0287 - val_root_mean_squared_error: 1.4221\n",
      "Epoch 2/60\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.1516 - mae: 0.3024 - mse: 0.1516 - root_mean_squared_error: 0.3461 - val_loss: 1.2610 - val_mae: 1.1174 - val_mse: 1.2610 - val_root_mean_squared_error: 1.1207\n",
      "Epoch 3/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0548 - mae: 0.1895 - mse: 0.0548 - root_mean_squared_error: 0.2304 - val_loss: 1.6815 - val_mae: 1.2920 - val_mse: 1.6815 - val_root_mean_squared_error: 1.2945\n",
      "Epoch 4/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0660 - mae: 0.2093 - mse: 0.0660 - root_mean_squared_error: 0.2515 - val_loss: 1.4346 - val_mae: 1.1926 - val_mse: 1.4346 - val_root_mean_squared_error: 1.1955\n",
      "Epoch 5/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0579 - mae: 0.1924 - mse: 0.0579 - root_mean_squared_error: 0.2299 - val_loss: 0.7921 - val_mae: 0.8830 - val_mse: 0.7921 - val_root_mean_squared_error: 0.8877\n",
      "Epoch 6/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0461 - mae: 0.1719 - mse: 0.0461 - root_mean_squared_error: 0.2072 - val_loss: 0.5257 - val_mae: 0.7165 - val_mse: 0.5257 - val_root_mean_squared_error: 0.7227\n",
      "Epoch 7/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0296 - mae: 0.1389 - mse: 0.0296 - root_mean_squared_error: 0.1701 - val_loss: 0.5183 - val_mae: 0.7113 - val_mse: 0.5183 - val_root_mean_squared_error: 0.7176\n",
      "Epoch 8/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0272 - mae: 0.1339 - mse: 0.0272 - root_mean_squared_error: 0.1629 - val_loss: 0.3355 - val_mae: 0.5684 - val_mse: 0.3355 - val_root_mean_squared_error: 0.5768\n",
      "Epoch 9/60\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0252 - mae: 0.1276 - mse: 0.0252 - root_mean_squared_error: 0.1577 - val_loss: 0.3709 - val_mae: 0.5988 - val_mse: 0.3709 - val_root_mean_squared_error: 0.6067\n",
      "Epoch 10/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0295 - mae: 0.1359 - mse: 0.0295 - root_mean_squared_error: 0.1689 - val_loss: 0.1986 - val_mae: 0.4316 - val_mse: 0.1986 - val_root_mean_squared_error: 0.4432\n",
      "Epoch 11/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0222 - mae: 0.1191 - mse: 0.0222 - root_mean_squared_error: 0.1473 - val_loss: 0.1825 - val_mae: 0.4124 - val_mse: 0.1825 - val_root_mean_squared_error: 0.4247\n",
      "Epoch 12/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0277 - mae: 0.1333 - mse: 0.0277 - root_mean_squared_error: 0.1640 - val_loss: 0.2129 - val_mae: 0.4478 - val_mse: 0.2129 - val_root_mean_squared_error: 0.4589\n",
      "Epoch 13/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0237 - mae: 0.1239 - mse: 0.0237 - root_mean_squared_error: 0.1529 - val_loss: 0.1191 - val_mae: 0.3268 - val_mse: 0.1191 - val_root_mean_squared_error: 0.3426\n",
      "Epoch 14/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0211 - mae: 0.1166 - mse: 0.0211 - root_mean_squared_error: 0.1444 - val_loss: 0.1137 - val_mae: 0.3183 - val_mse: 0.1137 - val_root_mean_squared_error: 0.3346\n",
      "Epoch 15/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0234 - mae: 0.1220 - mse: 0.0234 - root_mean_squared_error: 0.1515 - val_loss: 0.0907 - val_mae: 0.2800 - val_mse: 0.0907 - val_root_mean_squared_error: 0.2986\n",
      "Epoch 16/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0192 - mae: 0.1106 - mse: 0.0192 - root_mean_squared_error: 0.1366 - val_loss: 0.0610 - val_mae: 0.2221 - val_mse: 0.0610 - val_root_mean_squared_error: 0.2443\n",
      "Epoch 17/60\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.0212 - mae: 0.1198 - mse: 0.0212 - root_mean_squared_error: 0.1449 - val_loss: 0.0423 - val_mae: 0.1795 - val_mse: 0.0423 - val_root_mean_squared_error: 0.2031\n",
      "Epoch 18/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0206 - mae: 0.1158 - mse: 0.0206 - root_mean_squared_error: 0.1425 - val_loss: 0.0534 - val_mae: 0.2056 - val_mse: 0.0534 - val_root_mean_squared_error: 0.2286\n",
      "Epoch 19/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0193 - mae: 0.1122 - mse: 0.0193 - root_mean_squared_error: 0.1375 - val_loss: 0.0280 - val_mae: 0.1417 - val_mse: 0.0280 - val_root_mean_squared_error: 0.1649\n",
      "Epoch 20/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0174 - mae: 0.1085 - mse: 0.0174 - root_mean_squared_error: 0.1314 - val_loss: 0.0179 - val_mae: 0.1099 - val_mse: 0.0179 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 21/60\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0174 - mae: 0.1077 - mse: 0.0174 - root_mean_squared_error: 0.1309 - val_loss: 0.0145 - val_mae: 0.0981 - val_mse: 0.0145 - val_root_mean_squared_error: 0.1184\n",
      "Epoch 22/60\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0264 - mae: 0.1329 - mse: 0.0264 - root_mean_squared_error: 0.1588 - val_loss: 0.0134 - val_mae: 0.0941 - val_mse: 0.0134 - val_root_mean_squared_error: 0.1140\n",
      "Epoch 23/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0188 - mae: 0.1108 - mse: 0.0188 - root_mean_squared_error: 0.1353 - val_loss: 0.0134 - val_mae: 0.0942 - val_mse: 0.0134 - val_root_mean_squared_error: 0.1141\n",
      "Epoch 24/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0181 - mae: 0.1096 - mse: 0.0181 - root_mean_squared_error: 0.1337 - val_loss: 0.0161 - val_mae: 0.0989 - val_mse: 0.0161 - val_root_mean_squared_error: 0.1269\n",
      "Epoch 25/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0168 - mae: 0.1048 - mse: 0.0168 - root_mean_squared_error: 0.1286 - val_loss: 0.0123 - val_mae: 0.0875 - val_mse: 0.0123 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 26/60\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0172 - mae: 0.1075 - mse: 0.0172 - root_mean_squared_error: 0.1300 - val_loss: 0.0145 - val_mae: 0.0939 - val_mse: 0.0145 - val_root_mean_squared_error: 0.1203\n",
      "Epoch 27/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0173 - mae: 0.1070 - mse: 0.0173 - root_mean_squared_error: 0.1303 - val_loss: 0.0228 - val_mae: 0.1219 - val_mse: 0.0228 - val_root_mean_squared_error: 0.1515\n",
      "Epoch 28/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0181 - mae: 0.1089 - mse: 0.0181 - root_mean_squared_error: 0.1337 - val_loss: 0.0123 - val_mae: 0.0876 - val_mse: 0.0123 - val_root_mean_squared_error: 0.1100\n",
      "Epoch 29/60\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.0168 - mae: 0.1061 - mse: 0.0168 - root_mean_squared_error: 0.1287 - val_loss: 0.0170 - val_mae: 0.1018 - val_mse: 0.0170 - val_root_mean_squared_error: 0.1304\n",
      "Epoch 30/60\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0169 - mae: 0.1061 - mse: 0.0169 - root_mean_squared_error: 0.1286 - val_loss: 0.0305 - val_mae: 0.1458 - val_mse: 0.0305 - val_root_mean_squared_error: 0.1754\n",
      "Epoch 31/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0178 - mae: 0.1097 - mse: 0.0178 - root_mean_squared_error: 0.1324 - val_loss: 0.0194 - val_mae: 0.1104 - val_mse: 0.0194 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 32/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0161 - mae: 0.1043 - mse: 0.0161 - root_mean_squared_error: 0.1262 - val_loss: 0.0194 - val_mae: 0.1105 - val_mse: 0.0194 - val_root_mean_squared_error: 0.1396\n",
      "Epoch 33/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0164 - mae: 0.1060 - mse: 0.0164 - root_mean_squared_error: 0.1270 - val_loss: 0.0148 - val_mae: 0.0949 - val_mse: 0.0148 - val_root_mean_squared_error: 0.1216\n",
      "Epoch 34/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0172 - mae: 0.1053 - mse: 0.0172 - root_mean_squared_error: 0.1302 - val_loss: 0.0140 - val_mae: 0.0923 - val_mse: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 35/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0165 - mae: 0.1050 - mse: 0.0165 - root_mean_squared_error: 0.1278 - val_loss: 0.0200 - val_mae: 0.1127 - val_mse: 0.0200 - val_root_mean_squared_error: 0.1418\n",
      "Epoch 36/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0164 - mae: 0.1047 - mse: 0.0164 - root_mean_squared_error: 0.1277 - val_loss: 0.0191 - val_mae: 0.1095 - val_mse: 0.0191 - val_root_mean_squared_error: 0.1384\n",
      "Epoch 37/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0160 - mae: 0.1039 - mse: 0.0160 - root_mean_squared_error: 0.1260 - val_loss: 0.0254 - val_mae: 0.1301 - val_mse: 0.0254 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 38/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0162 - mae: 0.1049 - mse: 0.0162 - root_mean_squared_error: 0.1264 - val_loss: 0.0325 - val_mae: 0.1517 - val_mse: 0.0325 - val_root_mean_squared_error: 0.1810\n",
      "Epoch 39/60\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0160 - mae: 0.1034 - mse: 0.0160 - root_mean_squared_error: 0.1256 - val_loss: 0.0368 - val_mae: 0.1642 - val_mse: 0.0368 - val_root_mean_squared_error: 0.1927\n",
      "Epoch 40/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0164 - mae: 0.1046 - mse: 0.0164 - root_mean_squared_error: 0.1273 - val_loss: 0.0395 - val_mae: 0.1718 - val_mse: 0.0395 - val_root_mean_squared_error: 0.1998\n",
      "Epoch 41/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0159 - mae: 0.1034 - mse: 0.0159 - root_mean_squared_error: 0.1249 - val_loss: 0.0468 - val_mae: 0.1906 - val_mse: 0.0468 - val_root_mean_squared_error: 0.2174\n",
      "Epoch 42/60\n",
      "33/33 [==============================] - 3s 76ms/step - loss: 0.0159 - mae: 0.1033 - mse: 0.0159 - root_mean_squared_error: 0.1253 - val_loss: 0.0381 - val_mae: 0.1680 - val_mse: 0.0381 - val_root_mean_squared_error: 0.1963\n",
      "Epoch 43/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0157 - mae: 0.1025 - mse: 0.0157 - root_mean_squared_error: 0.1248 - val_loss: 0.0426 - val_mae: 0.1800 - val_mse: 0.0426 - val_root_mean_squared_error: 0.2075\n",
      "Epoch 44/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0161 - mae: 0.1040 - mse: 0.0161 - root_mean_squared_error: 0.1257 - val_loss: 0.0385 - val_mae: 0.1689 - val_mse: 0.0385 - val_root_mean_squared_error: 0.1971\n",
      "Epoch 45/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0156 - mae: 0.1029 - mse: 0.0156 - root_mean_squared_error: 0.1246 - val_loss: 0.0413 - val_mae: 0.1765 - val_mse: 0.0413 - val_root_mean_squared_error: 0.2042\n",
      "Epoch 46/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0158 - mae: 0.1033 - mse: 0.0158 - root_mean_squared_error: 0.1245 - val_loss: 0.0382 - val_mae: 0.1682 - val_mse: 0.0382 - val_root_mean_squared_error: 0.1964\n",
      "Epoch 47/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0158 - mae: 0.1024 - mse: 0.0158 - root_mean_squared_error: 0.1247 - val_loss: 0.0467 - val_mae: 0.1903 - val_mse: 0.0467 - val_root_mean_squared_error: 0.2172\n",
      "Epoch 48/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0158 - mae: 0.1037 - mse: 0.0158 - root_mean_squared_error: 0.1248 - val_loss: 0.0606 - val_mae: 0.2223 - val_mse: 0.0606 - val_root_mean_squared_error: 0.2473\n",
      "Epoch 49/60\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0156 - mae: 0.1027 - mse: 0.0156 - root_mean_squared_error: 0.1240 - val_loss: 0.0593 - val_mae: 0.2195 - val_mse: 0.0593 - val_root_mean_squared_error: 0.2446\n",
      "Epoch 50/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0162 - mae: 0.1035 - mse: 0.0162 - root_mean_squared_error: 0.1264 - val_loss: 0.0491 - val_mae: 0.1960 - val_mse: 0.0491 - val_root_mean_squared_error: 0.2226\n",
      "Epoch 51/60\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0157 - mae: 0.1030 - mse: 0.0157 - root_mean_squared_error: 0.1246 - val_loss: 0.0582 - val_mae: 0.2172 - val_mse: 0.0582 - val_root_mean_squared_error: 0.2425\n",
      "Epoch 52/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0157 - mae: 0.1024 - mse: 0.0157 - root_mean_squared_error: 0.1243 - val_loss: 0.0518 - val_mae: 0.2025 - val_mse: 0.0518 - val_root_mean_squared_error: 0.2288\n",
      "Epoch 53/60\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0157 - mae: 0.1029 - mse: 0.0157 - root_mean_squared_error: 0.1240 - val_loss: 0.0453 - val_mae: 0.1867 - val_mse: 0.0453 - val_root_mean_squared_error: 0.2138\n",
      "Epoch 54/60\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0158 - mae: 0.1029 - mse: 0.0158 - root_mean_squared_error: 0.1251 - val_loss: 0.0670 - val_mae: 0.2358 - val_mse: 0.0670 - val_root_mean_squared_error: 0.2601\n",
      "Epoch 55/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0159 - mae: 0.1031 - mse: 0.0159 - root_mean_squared_error: 0.1250 - val_loss: 0.0552 - val_mae: 0.2103 - val_mse: 0.0552 - val_root_mean_squared_error: 0.2360\n",
      "Epoch 56/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0158 - mae: 0.1030 - mse: 0.0158 - root_mean_squared_error: 0.1247 - val_loss: 0.0484 - val_mae: 0.1944 - val_mse: 0.0484 - val_root_mean_squared_error: 0.2211\n",
      "Epoch 57/60\n",
      "33/33 [==============================] - 3s 77ms/step - loss: 0.0159 - mae: 0.1037 - mse: 0.0159 - root_mean_squared_error: 0.1253 - val_loss: 0.0427 - val_mae: 0.1802 - val_mse: 0.0427 - val_root_mean_squared_error: 0.2077\n",
      "Epoch 58/60\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0159 - mae: 0.1030 - mse: 0.0159 - root_mean_squared_error: 0.1249 - val_loss: 0.0452 - val_mae: 0.1867 - val_mse: 0.0452 - val_root_mean_squared_error: 0.2137\n",
      "Epoch 59/60\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0159 - mae: 0.1033 - mse: 0.0159 - root_mean_squared_error: 0.1256 - val_loss: 0.0532 - val_mae: 0.2058 - val_mse: 0.0532 - val_root_mean_squared_error: 0.2319\n",
      "Epoch 60/60\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0157 - mae: 0.1034 - mse: 0.0157 - root_mean_squared_error: 0.1245 - val_loss: 0.0651 - val_mae: 0.2319 - val_mse: 0.0651 - val_root_mean_squared_error: 0.2563\n"
     ]
    }
   ],
   "source": [
    "# Train the manual model\n",
    "history_manual = manual_model.fit(train_data_inputs, train_data_targets,\n",
    "          validation_data=(val_data_inputs, val_data_targets),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "33/33 [==============================] - 85s 2s/step - loss: 2.9154 - mae: 0.9892 - mse: 2.9154 - root_mean_squared_error: 1.0030 - val_loss: 0.4153 - val_mae: 0.6348 - val_mse: 0.4153 - val_root_mean_squared_error: 0.6461\n",
      "Epoch 2/60\n",
      "33/33 [==============================] - 60s 2s/step - loss: 0.1128 - mae: 0.2801 - mse: 0.1128 - root_mean_squared_error: 0.3079 - val_loss: 1.3435 - val_mae: 1.1538 - val_mse: 1.3435 - val_root_mean_squared_error: 1.1610\n",
      "Epoch 3/60\n",
      "33/33 [==============================] - 59s 2s/step - loss: 0.0280 - mae: 0.1358 - mse: 0.0280 - root_mean_squared_error: 0.1645 - val_loss: 1.5831 - val_mae: 1.2533 - val_mse: 1.5831 - val_root_mean_squared_error: 1.2601\n",
      "Epoch 4/60\n",
      "33/33 [==============================] - 59s 2s/step - loss: 0.0842 - mae: 0.2297 - mse: 0.0842 - root_mean_squared_error: 0.2559 - val_loss: 1.1548 - val_mae: 1.0689 - val_mse: 1.1548 - val_root_mean_squared_error: 1.0764\n",
      "Epoch 5/60\n",
      "33/33 [==============================] - 58s 2s/step - loss: 0.0465 - mae: 0.1760 - mse: 0.0465 - root_mean_squared_error: 0.2033 - val_loss: 0.7692 - val_mae: 0.8700 - val_mse: 0.7692 - val_root_mean_squared_error: 0.8788\n",
      "Epoch 6/60\n",
      "33/33 [==============================] - 58s 2s/step - loss: 0.0367 - mae: 0.1525 - mse: 0.0367 - root_mean_squared_error: 0.1784 - val_loss: 0.5666 - val_mae: 0.7445 - val_mse: 0.5666 - val_root_mean_squared_error: 0.7545\n",
      "Epoch 7/60\n",
      "33/33 [==============================] - 59s 2s/step - loss: 0.0292 - mae: 0.1375 - mse: 0.0292 - root_mean_squared_error: 0.1648 - val_loss: 0.5621 - val_mae: 0.7414 - val_mse: 0.5621 - val_root_mean_squared_error: 0.7515\n",
      "Epoch 8/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0354 - mae: 0.1530 - mse: 0.0354 - root_mean_squared_error: 0.1815 - val_loss: 0.8115 - val_mae: 0.8940 - val_mse: 0.8115 - val_root_mean_squared_error: 0.9026\n",
      "Epoch 9/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0256 - mae: 0.1287 - mse: 0.0256 - root_mean_squared_error: 0.1572 - val_loss: 0.5196 - val_mae: 0.7122 - val_mse: 0.5196 - val_root_mean_squared_error: 0.7226\n",
      "Epoch 10/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0422 - mae: 0.1683 - mse: 0.0422 - root_mean_squared_error: 0.1989 - val_loss: 0.2955 - val_mae: 0.5322 - val_mse: 0.2955 - val_root_mean_squared_error: 0.5453\n",
      "Epoch 11/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0248 - mae: 0.1279 - mse: 0.0248 - root_mean_squared_error: 0.1551 - val_loss: 0.3764 - val_mae: 0.6034 - val_mse: 0.3764 - val_root_mean_squared_error: 0.6152\n",
      "Epoch 12/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0197 - mae: 0.1137 - mse: 0.0197 - root_mean_squared_error: 0.1391 - val_loss: 0.1841 - val_mae: 0.4145 - val_mse: 0.1841 - val_root_mean_squared_error: 0.4306\n",
      "Epoch 13/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0242 - mae: 0.1274 - mse: 0.0242 - root_mean_squared_error: 0.1524 - val_loss: 0.2810 - val_mae: 0.5184 - val_mse: 0.2810 - val_root_mean_squared_error: 0.5317\n",
      "Epoch 14/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0177 - mae: 0.1074 - mse: 0.0177 - root_mean_squared_error: 0.1320 - val_loss: 0.2205 - val_mae: 0.4563 - val_mse: 0.2205 - val_root_mean_squared_error: 0.4712\n",
      "Epoch 15/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0173 - mae: 0.1077 - mse: 0.0173 - root_mean_squared_error: 0.1307 - val_loss: 0.3174 - val_mae: 0.5523 - val_mse: 0.3174 - val_root_mean_squared_error: 0.5650\n",
      "Epoch 16/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0177 - mae: 0.1077 - mse: 0.0177 - root_mean_squared_error: 0.1322 - val_loss: 0.1802 - val_mae: 0.4097 - val_mse: 0.1802 - val_root_mean_squared_error: 0.4260\n",
      "Epoch 17/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0170 - mae: 0.1060 - mse: 0.0170 - root_mean_squared_error: 0.1293 - val_loss: 0.2336 - val_mae: 0.4704 - val_mse: 0.2336 - val_root_mean_squared_error: 0.4849\n",
      "Epoch 18/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0181 - mae: 0.1083 - mse: 0.0181 - root_mean_squared_error: 0.1333 - val_loss: 0.1827 - val_mae: 0.4128 - val_mse: 0.1827 - val_root_mean_squared_error: 0.4290\n",
      "Epoch 19/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0165 - mae: 0.1053 - mse: 0.0165 - root_mean_squared_error: 0.1275 - val_loss: 0.1743 - val_mae: 0.4024 - val_mse: 0.1743 - val_root_mean_squared_error: 0.4190\n",
      "Epoch 20/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0182 - mae: 0.1086 - mse: 0.0182 - root_mean_squared_error: 0.1336 - val_loss: 0.1585 - val_mae: 0.3823 - val_mse: 0.1585 - val_root_mean_squared_error: 0.3996\n",
      "Epoch 21/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0166 - mae: 0.1056 - mse: 0.0166 - root_mean_squared_error: 0.1279 - val_loss: 0.1652 - val_mae: 0.3909 - val_mse: 0.1652 - val_root_mean_squared_error: 0.4079\n",
      "Epoch 22/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0174 - mae: 0.1070 - mse: 0.0174 - root_mean_squared_error: 0.1309 - val_loss: 0.1244 - val_mae: 0.3348 - val_mse: 0.1244 - val_root_mean_squared_error: 0.3541\n",
      "Epoch 23/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0164 - mae: 0.1044 - mse: 0.0164 - root_mean_squared_error: 0.1277 - val_loss: 0.1251 - val_mae: 0.3358 - val_mse: 0.1251 - val_root_mean_squared_error: 0.3551\n",
      "Epoch 24/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0175 - mae: 0.1070 - mse: 0.0175 - root_mean_squared_error: 0.1314 - val_loss: 0.1343 - val_mae: 0.3492 - val_mse: 0.1343 - val_root_mean_squared_error: 0.3679\n",
      "Epoch 25/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0169 - mae: 0.1058 - mse: 0.0169 - root_mean_squared_error: 0.1292 - val_loss: 0.1233 - val_mae: 0.3332 - val_mse: 0.1233 - val_root_mean_squared_error: 0.3526\n",
      "Epoch 26/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0163 - mae: 0.1039 - mse: 0.0163 - root_mean_squared_error: 0.1272 - val_loss: 0.1104 - val_mae: 0.3131 - val_mse: 0.1104 - val_root_mean_squared_error: 0.3336\n",
      "Epoch 27/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0169 - mae: 0.1055 - mse: 0.0169 - root_mean_squared_error: 0.1293 - val_loss: 0.0956 - val_mae: 0.2888 - val_mse: 0.0956 - val_root_mean_squared_error: 0.3105\n",
      "Epoch 28/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0167 - mae: 0.1060 - mse: 0.0167 - root_mean_squared_error: 0.1287 - val_loss: 0.0994 - val_mae: 0.2953 - val_mse: 0.0994 - val_root_mean_squared_error: 0.3167\n",
      "Epoch 29/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0161 - mae: 0.1037 - mse: 0.0161 - root_mean_squared_error: 0.1260 - val_loss: 0.0860 - val_mae: 0.2720 - val_mse: 0.0860 - val_root_mean_squared_error: 0.2946\n",
      "Epoch 30/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0158 - mae: 0.1036 - mse: 0.0158 - root_mean_squared_error: 0.1252 - val_loss: 0.0933 - val_mae: 0.2847 - val_mse: 0.0933 - val_root_mean_squared_error: 0.3067\n",
      "Epoch 31/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0162 - mae: 0.1038 - mse: 0.0162 - root_mean_squared_error: 0.1266 - val_loss: 0.0848 - val_mae: 0.2698 - val_mse: 0.0848 - val_root_mean_squared_error: 0.2925\n",
      "Epoch 32/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0160 - mae: 0.1034 - mse: 0.0160 - root_mean_squared_error: 0.1257 - val_loss: 0.0868 - val_mae: 0.2733 - val_mse: 0.0868 - val_root_mean_squared_error: 0.2959\n",
      "Epoch 33/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0165 - mae: 0.1047 - mse: 0.0165 - root_mean_squared_error: 0.1276 - val_loss: 0.0867 - val_mae: 0.2733 - val_mse: 0.0867 - val_root_mean_squared_error: 0.2958\n",
      "Epoch 34/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0157 - mae: 0.1024 - mse: 0.0157 - root_mean_squared_error: 0.1244 - val_loss: 0.0582 - val_mae: 0.2170 - val_mse: 0.0582 - val_root_mean_squared_error: 0.2423\n",
      "Epoch 35/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0158 - mae: 0.1036 - mse: 0.0158 - root_mean_squared_error: 0.1248 - val_loss: 0.0774 - val_mae: 0.2563 - val_mse: 0.0774 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 36/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0160 - mae: 0.1040 - mse: 0.0160 - root_mean_squared_error: 0.1254 - val_loss: 0.0588 - val_mae: 0.2184 - val_mse: 0.0588 - val_root_mean_squared_error: 0.2436\n",
      "Epoch 37/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0156 - mae: 0.1022 - mse: 0.0156 - root_mean_squared_error: 0.1243 - val_loss: 0.0642 - val_mae: 0.2301 - val_mse: 0.0642 - val_root_mean_squared_error: 0.2546\n",
      "Epoch 38/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0156 - mae: 0.1022 - mse: 0.0156 - root_mean_squared_error: 0.1241 - val_loss: 0.0510 - val_mae: 0.2006 - val_mse: 0.0510 - val_root_mean_squared_error: 0.2269\n",
      "Epoch 39/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0160 - mae: 0.1044 - mse: 0.0160 - root_mean_squared_error: 0.1253 - val_loss: 0.0497 - val_mae: 0.1976 - val_mse: 0.0497 - val_root_mean_squared_error: 0.2241\n",
      "Epoch 40/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0160 - mae: 0.1037 - mse: 0.0160 - root_mean_squared_error: 0.1257 - val_loss: 0.0561 - val_mae: 0.2124 - val_mse: 0.0561 - val_root_mean_squared_error: 0.2380\n",
      "Epoch 41/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0159 - mae: 0.1033 - mse: 0.0159 - root_mean_squared_error: 0.1254 - val_loss: 0.0456 - val_mae: 0.1874 - val_mse: 0.0456 - val_root_mean_squared_error: 0.2145\n",
      "Epoch 42/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0158 - mae: 0.1030 - mse: 0.0158 - root_mean_squared_error: 0.1242 - val_loss: 0.0618 - val_mae: 0.2249 - val_mse: 0.0618 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 43/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0158 - mae: 0.1036 - mse: 0.0158 - root_mean_squared_error: 0.1253 - val_loss: 0.0674 - val_mae: 0.2366 - val_mse: 0.0674 - val_root_mean_squared_error: 0.2608\n",
      "Epoch 44/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0158 - mae: 0.1031 - mse: 0.0158 - root_mean_squared_error: 0.1250 - val_loss: 0.0575 - val_mae: 0.2156 - val_mse: 0.0575 - val_root_mean_squared_error: 0.2410\n",
      "Epoch 45/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0161 - mae: 0.1039 - mse: 0.0161 - root_mean_squared_error: 0.1261 - val_loss: 0.0577 - val_mae: 0.2159 - val_mse: 0.0577 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 46/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0157 - mae: 0.1029 - mse: 0.0157 - root_mean_squared_error: 0.1244 - val_loss: 0.0540 - val_mae: 0.2075 - val_mse: 0.0540 - val_root_mean_squared_error: 0.2335\n",
      "Epoch 47/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0156 - mae: 0.1027 - mse: 0.0156 - root_mean_squared_error: 0.1238 - val_loss: 0.0687 - val_mae: 0.2392 - val_mse: 0.0687 - val_root_mean_squared_error: 0.2633\n",
      "Epoch 48/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0158 - mae: 0.1032 - mse: 0.0158 - root_mean_squared_error: 0.1252 - val_loss: 0.0640 - val_mae: 0.2296 - val_mse: 0.0640 - val_root_mean_squared_error: 0.2542\n",
      "Epoch 49/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0157 - mae: 0.1030 - mse: 0.0157 - root_mean_squared_error: 0.1247 - val_loss: 0.0692 - val_mae: 0.2403 - val_mse: 0.0692 - val_root_mean_squared_error: 0.2643\n",
      "Epoch 50/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0157 - mae: 0.1021 - mse: 0.0157 - root_mean_squared_error: 0.1241 - val_loss: 0.0508 - val_mae: 0.2002 - val_mse: 0.0508 - val_root_mean_squared_error: 0.2266\n",
      "Epoch 51/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0162 - mae: 0.1036 - mse: 0.0162 - root_mean_squared_error: 0.1265 - val_loss: 0.0602 - val_mae: 0.2214 - val_mse: 0.0602 - val_root_mean_squared_error: 0.2465\n",
      "Epoch 52/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0157 - mae: 0.1030 - mse: 0.0157 - root_mean_squared_error: 0.1243 - val_loss: 0.0501 - val_mae: 0.1984 - val_mse: 0.0501 - val_root_mean_squared_error: 0.2249\n",
      "Epoch 53/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0158 - mae: 0.1035 - mse: 0.0158 - root_mean_squared_error: 0.1251 - val_loss: 0.0439 - val_mae: 0.1833 - val_mse: 0.0439 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 54/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0158 - mae: 0.1033 - mse: 0.0158 - root_mean_squared_error: 0.1252 - val_loss: 0.0646 - val_mae: 0.2308 - val_mse: 0.0646 - val_root_mean_squared_error: 0.2553\n",
      "Epoch 55/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0157 - mae: 0.1023 - mse: 0.0157 - root_mean_squared_error: 0.1236 - val_loss: 0.0577 - val_mae: 0.2159 - val_mse: 0.0577 - val_root_mean_squared_error: 0.2413\n",
      "Epoch 56/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0159 - mae: 0.1037 - mse: 0.0159 - root_mean_squared_error: 0.1254 - val_loss: 0.0555 - val_mae: 0.2109 - val_mse: 0.0555 - val_root_mean_squared_error: 0.2366\n",
      "Epoch 57/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0161 - mae: 0.1037 - mse: 0.0161 - root_mean_squared_error: 0.1261 - val_loss: 0.0508 - val_mae: 0.2000 - val_mse: 0.0508 - val_root_mean_squared_error: 0.2264\n",
      "Epoch 58/60\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.0175 - mae: 0.1079 - mse: 0.0175 - root_mean_squared_error: 0.1308 - val_loss: 0.0510 - val_mae: 0.2006 - val_mse: 0.0510 - val_root_mean_squared_error: 0.2269\n",
      "Epoch 59/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0158 - mae: 0.1033 - mse: 0.0158 - root_mean_squared_error: 0.1248 - val_loss: 0.0572 - val_mae: 0.2147 - val_mse: 0.0572 - val_root_mean_squared_error: 0.2402\n",
      "Epoch 60/60\n",
      "33/33 [==============================] - 55s 2s/step - loss: 0.0159 - mae: 0.1033 - mse: 0.0159 - root_mean_squared_error: 0.1253 - val_loss: 0.0617 - val_mae: 0.2248 - val_mse: 0.0617 - val_root_mean_squared_error: 0.2497\n"
     ]
    }
   ],
   "source": [
    "# Train the keras model\n",
    "history_keras = keras_model.fit(train_data_inputs, train_data_targets,\n",
    "          validation_data=(val_data_inputs, val_data_targets),\n",
    "          epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1368x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history, model_name, ax):\n",
    "    ax.plot(history.history['loss'], label='Training Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training and Validation Loss for ' + model_name)\n",
    "    ax.legend()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(19, 8))\n",
    "\n",
    "histories = [history_manual, history_keras]\n",
    "model_names = ['Manual Transformer', 'Keras Transformer']\n",
    "\n",
    "for history, model_name, ax in zip(histories, model_names, axes):\n",
    "    plot_loss(history, model_name, ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0651 - mae: 0.2319 - mse: 0.0651 - root_mean_squared_error: 0.2563\n",
      "7/7 [==============================] - 4s 500ms/step - loss: 0.0617 - mae: 0.2248 - mse: 0.0617 - root_mean_squared_error: 0.2497\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2578 - mae: 0.4876 - mse: 0.2578 - root_mean_squared_error: 0.5113\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.2507 - mae: 0.4802 - mse: 0.2507 - root_mean_squared_error: 0.5042\n",
      "\n",
      "\n",
      "Manual Transformer:\n",
      "-------------------\n",
      "Validation Loss: 0.0650780200958252, Validation MSE: 0.0650780200958252, Validation MAE: 0.2318592518568039, Validation RMSE: 0.2563035190105438\n",
      "Test Loss: 0.2578379213809967, Test MSE: 0.2578379213809967, Test MAE: 0.48759832978248596, Test RMSE: 0.5112890005111694\n",
      "\n",
      "Keras Transformer:\n",
      "------------------\n",
      "Validation Loss: 0.061748918145895004, Validation MSE: 0.061748918145895004, Validation MAE: 0.224838525056839, Validation RMSE: 0.24967142939567566\n",
      "Test Loss: 0.250718355178833, Test MSE: 0.250718355178833, Test MAE: 0.48024246096611023, Test RMSE: 0.5042287707328796\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_metrics_manual = manual_model.evaluate(val_data_inputs, val_data_targets, return_dict=True)\n",
    "val_metrics_keras = keras_model.evaluate(val_data_inputs, val_data_targets, return_dict=True)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics_manual = manual_model.evaluate(test_data_inputs, test_data_targets, return_dict=True)\n",
    "test_metrics_keras = keras_model.evaluate(test_data_inputs, test_data_targets, return_dict=True)\n",
    "\n",
    "# Extract individual metrics\n",
    "val_loss_manual, val_mae_manual, val_mse_manual, val_rmse_manual = val_metrics_manual['loss'], val_metrics_manual['mae'], val_metrics_manual['mse'], val_metrics_manual['root_mean_squared_error']\n",
    "test_loss_manual, test_mae_manual, test_mse_manual, test_rmse_manual = test_metrics_manual['loss'], test_metrics_manual['mae'], test_metrics_manual['mse'], test_metrics_manual['root_mean_squared_error']\n",
    "\n",
    "val_loss_keras, val_mae_keras, val_mse_keras, val_rmse_keras = val_metrics_keras['loss'], val_metrics_keras['mae'], val_metrics_keras['mse'], val_metrics_keras['root_mean_squared_error']\n",
    "test_loss_keras, test_mae_keras, test_mse_keras, test_rmse_keras = test_metrics_keras['loss'], test_metrics_keras['mae'], test_metrics_keras['mse'], test_metrics_keras['root_mean_squared_error']\n",
    "\n",
    "print('\\n\\nManual Transformer:\\n-------------------')\n",
    "print(f'Validation Loss: {val_loss_manual}, Validation MSE: {val_mse_manual}, Validation MAE: {val_mae_manual}, Validation RMSE: {val_rmse_manual}')\n",
    "print(f'Test Loss: {test_loss_manual}, Test MSE: {test_mse_manual}, Test MAE: {test_mae_manual}, Test RMSE: {test_rmse_manual}')\n",
    "\n",
    "print('\\nKeras Transformer:\\n------------------')\n",
    "print(f'Validation Loss: {val_loss_keras}, Validation MSE: {val_mse_keras}, Validation MAE: {val_mae_keras}, Validation RMSE: {val_rmse_keras}')\n",
    "print(f'Test Loss: {test_loss_keras}, Test MSE: {test_mse_keras}, Test MAE: {test_mae_keras}, Test RMSE: {test_rmse_keras}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 21ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "7/7 [==============================] - 6s 491ms/step\n",
      "2/2 [==============================] - 1s 185ms/step\n",
      "\n",
      "\n",
      "Manual Transformer:\n",
      "-------------------\n",
      "Validation MAE: 0.23185890913009644\n",
      "Validation RMSE: 0.25510385632514954\n",
      "\n",
      "Test MAE: 0.4875982821722668\n",
      "Test RMSE: 0.5077771401856632\n",
      "\n",
      "==============================\n",
      "\n",
      "Keras Transformer:\n",
      "------------------\n",
      "Validation MAE: 0.2248385101556778\n",
      "Validation RMSE: 0.2484932839870453\n",
      "\n",
      "Test MAE: 0.4802424425373317\n",
      "Test RMSE: 0.5007178276326735\n"
     ]
    }
   ],
   "source": [
    "# Assuming manual_model.predict returns the predictions\n",
    "val_predictions_manual = manual_model.predict(val_data_inputs)\n",
    "test_predictions_manual = manual_model.predict(test_data_inputs)\n",
    "\n",
    "# Assuming keras_model.predict returns the predictions\n",
    "val_predictions_keras = keras_model.predict(val_data_inputs)\n",
    "test_predictions_keras  = keras_model.predict(test_data_inputs)\n",
    "\n",
    "# Calculate MAE and RMSE for validation set\n",
    "val_mae_manual = np.mean(np.abs(val_data_targets - val_predictions_manual))\n",
    "val_rmse_manual = np.sqrt(np.mean(np.square(val_data_targets - val_predictions_manual)))\n",
    "\n",
    "val_mae_keras  = np.mean(np.abs(val_data_targets - val_predictions_keras ))\n",
    "val_rmse_keras  = np.sqrt(np.mean(np.square(val_data_targets - val_predictions_keras )))\n",
    "\n",
    "# Calculate MAE and RMSE for test set\n",
    "test_mae_manual = np.mean(np.abs(test_data_targets - test_predictions_manual))\n",
    "test_rmse_manual = np.sqrt(np.mean(np.square(test_data_targets - test_predictions_manual)))\n",
    "\n",
    "test_mae_keras  = np.mean(np.abs(test_data_targets - test_predictions_keras ))\n",
    "test_rmse_keras  = np.sqrt(np.mean(np.square(test_data_targets - test_predictions_keras )))\n",
    "\n",
    "\n",
    "print('\\n\\nManual Transformer:\\n-------------------')\n",
    "print(f'Validation MAE: {val_mae_manual}')\n",
    "print(f'Validation RMSE: {val_rmse_manual}')\n",
    "print(f'\\nTest MAE: {test_mae_manual}')\n",
    "print(f'Test RMSE: {test_rmse_manual}')\n",
    "print('\\n==============================')\n",
    "print('\\nKeras Transformer:\\n------------------')\n",
    "print(f'Validation MAE: {val_mae_keras }')\n",
    "print(f'Validation RMSE: {val_rmse_keras }')\n",
    "print(f'\\nTest MAE: {test_mae_keras }')\n",
    "print(f'Test RMSE: {test_rmse_keras }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 22ms/step\n",
      "7/7 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "\n",
      "\n",
      "Evaluation metrics for Keras Transformer model:\n",
      "-------------------\n",
      "Train Dataset:\n",
      "RMSE: 90.94998311755359\n",
      "MAE: 73.36830251285554\n",
      "-------------------\n",
      "Validation Dataset:\n",
      "RMSE: 184.90009556572247\n",
      "Validation MAE: 168.05227706425188\n",
      "-------------------\n",
      "Test Dataset:\n",
      "Test RMSE: 368.03858757727494\n",
      "Test MAE: 353.41269771330553\n",
      "\n",
      "\n",
      "33/33 [==============================] - 17s 528ms/step\n",
      "7/7 [==============================] - 3s 495ms/step\n",
      "2/2 [==============================] - 1s 172ms/step\n",
      "\n",
      "\n",
      "Evaluation metrics for Keras Transformer model:\n",
      "-------------------\n",
      "Train Dataset:\n",
      "RMSE: 90.39176174911539\n",
      "MAE: 73.55249151812548\n",
      "-------------------\n",
      "Validation Dataset:\n",
      "RMSE: 180.10868082355802\n",
      "Validation MAE: 162.96363174697902\n",
      "-------------------\n",
      "Test Dataset:\n",
      "Test RMSE: 362.92178357951065\n",
      "Test MAE: 348.08116307838577\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions_model(model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler):\n",
    "    # Predictions on training data\n",
    "    y_pred_train = model.predict(train_data_inputs)\n",
    "    inversed_y_pred_train = scaler.inverse_transform(np.concatenate([y_pred_train, np.zeros((y_pred_train.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_train = inversed_y_pred_train[:, 0]\n",
    "\n",
    "    # Inverse the target train data\n",
    "    train_targets_scaled_data = train_data_targets.reshape(-1,1)\n",
    "    train_targets_data = scaler.inverse_transform(np.concatenate([train_targets_scaled_data, np.zeros((train_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    train_targets_data = train_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on training data\n",
    "    train_rmse = calculate_rmse(train_targets_data, inversed_y_pred_train)\n",
    "    train_mae = calculate_mae(train_targets_data, inversed_y_pred_train)\n",
    "\n",
    "    # Predictions on validation data\n",
    "    y_pred_val = model.predict(val_data_inputs)\n",
    "    inversed_y_pred_val = scaler.inverse_transform(np.concatenate([y_pred_val, np.zeros((y_pred_val.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_val = inversed_y_pred_val[:, 0]\n",
    "    \n",
    "    # Inverse the target validation data\n",
    "    val_targets_scaled_data = val_data_targets.reshape(-1,1)\n",
    "    val_targets_data = scaler.inverse_transform(np.concatenate([val_targets_scaled_data, np.zeros((val_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    val_targets_data = val_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on validation data\n",
    "    val_rmse = calculate_rmse(val_targets_data, inversed_y_pred_val)\n",
    "    val_mae = calculate_mae(val_targets_data, inversed_y_pred_val)\n",
    "\n",
    "    # Predictions on test data\n",
    "    y_pred_test = model.predict(test_data_inputs)\n",
    "    inversed_y_pred_test = scaler.inverse_transform(np.concatenate([y_pred_test, np.zeros((y_pred_test.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    inversed_y_pred_test = inversed_y_pred_test[:, 0]\n",
    "\n",
    "    test_targets_scaled_data = test_data_targets.reshape(-1,1)\n",
    "    test_targets_data = scaler.inverse_transform(np.concatenate([test_targets_scaled_data, np.zeros((test_targets_scaled_data.shape[0], scaler.n_features_in_-1))], axis=1))\n",
    "    test_targets_data = test_targets_data[:, 0]\n",
    "\n",
    "    # Metrics on test data\n",
    "    test_rmse = calculate_rmse(test_targets_data, inversed_y_pred_test)\n",
    "    test_mae = calculate_mae(test_targets_data, inversed_y_pred_test)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\n\\nEvaluation metrics for {model_name} model:\\n-------------------\")\n",
    "    print('Train Dataset:')\n",
    "    print(f\"RMSE: {train_rmse}\")\n",
    "    print(f\"MAE: {train_mae}\\n-------------------\")\n",
    "\n",
    "    print('Validation Dataset:')\n",
    "    print(f\"RMSE: {val_rmse}\")\n",
    "    print(f\"Validation MAE: {val_mae}\\n-------------------\")\n",
    "    \n",
    "    print('Test Dataset:')\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "    print(f\"Test MAE: {test_mae}\\n\\n\")\n",
    "\n",
    "evaluate_predictions_model(manual_model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler)\n",
    "evaluate_predictions_model(keras_model, model_name, train_data_inputs, train_data_targets, val_data_inputs, val_data_targets, test_data_inputs, test_data_targets, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
