{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import calendar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Weather Data <br><br>\n",
    "\n",
    "Source of Data: https://psl.noaa.gov/boulder/data.daily.html <br>\n",
    "querie code: var i = 1; [].forEach.call(document.querySelectorAll('table'), function(x) { console.log(i++, x); });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1/1/2018 17:49', '9/9/2023 9:19')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/BOULDER_Electric_Vehicle_Charging_Station_Data.csv')\n",
    "\n",
    "df.Start_Date___Time.min(), df.Start_Date___Time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2018': [195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217],\n",
       " '2019': [219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241],\n",
       " '2020': [243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265],\n",
       " '2021': [267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289],\n",
       " '2022': [291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313],\n",
       " '2023': [315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These tables contains the indexes of weather data tables for the period Jan-2018 to Nov-2023\n",
    "tables_year = {'2018': [num for num in range(195, 218, 2)],\n",
    "               '2019': [num for num in range(219, 242, 2)],\n",
    "               '2020': [num for num in range(243, 266, 2)],\n",
    "               '2021': [num for num in range(267, 290, 2)],\n",
    "               '2022': [num for num in range(291, 314, 2)],\n",
    "               '2023': [num for num in range(315, 336, 2)]}\n",
    "\n",
    "tables_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source of Implementation: - https://towardsdatascience.com/a-guide-to-scraping-html-tables-with-pandas-and-beautifulsoup-7fc24c331cf7\n",
    "\n",
    "#                           - https://github.com/SwethaSrikari/Predicting-EV-charging-demand/blob/main/Web_scraping_Colorado_weather.ipynb\n",
    "\n",
    "\n",
    "# Function to scrape weather data table for a specific year from a given URL\n",
    "def get_weather_data_table_basedOnYear(url, year):\n",
    "    # Send a GET request to the specified URL\n",
    "    page = requests.get(url) \n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(page.text, 'html.parser') \n",
    "    \n",
    "    rows = [] # Initialize an empty list to store rows of data\n",
    "\n",
    "    # Loop through the tables associated with the specified year\n",
    "    for table in tables_year[year]: \n",
    "\n",
    "        # Loop through the children of the table element\n",
    "        for i, child in enumerate(soup.find_all('table')[table].children): \n",
    "            row = [] # Initialize an empty list to store data for each row\n",
    "\n",
    "            # Loop through the cells (td elements) in the row\n",
    "            for td in child: \n",
    "                try:\n",
    "                    row.append(td.text) # Attempt to extract text content from each cell and append to the row list\n",
    "                except:\n",
    "                    continue # If an exception occurs (e.g., if the cell is not a td element), continue to the next iteration\n",
    "\n",
    "            # Check if the row contains any data (i.e., if it's not an empty row)\n",
    "            if len(row) > 0:\n",
    "                rows.append(row) # Append the non-empty row to the list of rows\n",
    "\n",
    "    # Create a DataFrame using the extracted rows, specifying columns and dropping duplicate rows\n",
    "    df = pd.DataFrame(rows[1:], columns=rows[0]).drop_duplicates(keep=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes of DataFrames: (366, 8) (366, 8) (366, 8) (366, 8) (366, 8)\n"
     ]
    }
   ],
   "source": [
    "# Define the url source\n",
    "url = 'https://psl.noaa.gov/boulder/data.daily.html'\n",
    "\n",
    "# Take the Weather Data Tables for each year\n",
    "df_2018 = get_weather_data_table_basedOnYear(url, str(2018))\n",
    "df_2019 = get_weather_data_table_basedOnYear(url, str(2019))\n",
    "df_2020 = get_weather_data_table_basedOnYear(url, str(2020))\n",
    "df_2021 = get_weather_data_table_basedOnYear(url, str(2021))\n",
    "df_2022 = get_weather_data_table_basedOnYear(url, str(2022))\n",
    "df_2023 = get_weather_data_table_basedOnYear(url, str(2023))\n",
    "\n",
    "print('\\nShapes of DataFrames:',df_2018.shape, df_2019.shape, df_2020.shape, df_2021.shape, df_2022.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Weather Data <br><br>\n",
    "Source of the weather data cleaning: https://psl.noaa.gov/boulder/getdata.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows containing 'Miss' in df_2018 are/is: 1\n",
      "Number of rows containing 'Miss' in df_2019 are/is: 1\n",
      "Number of rows containing 'Miss' in df_2020 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2021 are/is: 1\n",
      "Number of rows containing 'Miss' in df_2022 are/is: 1\n",
      "Number of rows containing 'Miss' in df_2023 are/is: 1\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of rows containing the word 'Miss' in multiple DataFrames\n",
    "for year in range(2018, 2024):\n",
    "    miss_count = locals()[f'df_{year}'].apply(lambda row: any(row == 'Miss '), axis=1).sum()\n",
    "    print(f\"Number of rows containing 'Miss' in df_{year} are/is: {miss_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining data from multiple DataFrames (df_2018 to df_2023), we observed one row containing the value 'Miss' in each DataFrame, outside of df_2020. This occurrence is attributed to leap years, where February 29th is not present, leading to the 'Miss' value in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for leap years\n",
    "def is_leap_year(year):\n",
    "    return calendar.isleap(year)\n",
    "\n",
    "\n",
    "# Function to remove leading and trailing spaces from a string value\n",
    "def strip_spaces(value):\n",
    "    # Check if the value is a string before applying strip()\n",
    "    return value.strip() if isinstance(value, str) else value\n",
    "\n",
    "\n",
    "\n",
    "# Function to prepare weather data\n",
    "def prepare_weather_data(df):\n",
    "    \n",
    "    # Clean column names by removing extra spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Remove extra spaces from all rows in the DataFrame\n",
    "    df = df.applymap(strip_spaces)\n",
    "\n",
    "    # Handle 'T' as a trace (less than 0.01 inches for precipitation and 0.1 for snow)\n",
    "    df[\"Snow\"] = df[\"Snow\"].replace('T', 0.099)\n",
    "    df[\"Precipitation\"] = df[\"Precipitation\"].replace('T', 0.0099)\n",
    "\n",
    "    # Exclude rows with 'Miss' from the DataFrame\n",
    "    df = df.loc[~(df == 'Miss').any(axis=1)]\n",
    "\n",
    "    # Convert year, month, day to numeric\n",
    "    df[[\"Year\", \"Month\", \"Day\"]] = df[[\"Year\", \"Month\", \"Day\"]].apply(pd.to_numeric)\n",
    "\n",
    "    # Handle February based on leap year\n",
    "    mask = (df[\"Month\"] == 2) & (df[\"Day\"] == 29) & ~df[\"Year\"].apply(is_leap_year)\n",
    "    # If the mask is true for a row, set the value of the \"Day\" column to 28\n",
    "    df.loc[mask, \"Day\"] = 28\n",
    "\n",
    "    # Convert specified columns to numeric and remove 'Snow Depth' column\n",
    "    df = df[[\"Year\", \"Month\", \"Day\", \"Maximum T\", \"Minimum T\", \"Precipitation\", \"Snow\"]].apply(pd.to_numeric)\n",
    "\n",
    "    # Create a date column\n",
    "    df[\"Date\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]]).dt.date.astype(\"datetime64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean the Weather Data Tables for each year\n",
    "df_2018 = prepare_weather_data(df_2018)\n",
    "df_2019 = prepare_weather_data(df_2019)\n",
    "df_2020 = prepare_weather_data(df_2020)\n",
    "df_2021 = prepare_weather_data(df_2021)\n",
    "df_2022 = prepare_weather_data(df_2022)\n",
    "df_2023 = prepare_weather_data(df_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows containing 'Miss' in df_2018 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2019 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2020 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2021 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2022 are/is: 0\n",
      "Number of rows containing 'Miss' in df_2023 are/is: 0\n",
      "\n",
      "Shapes of DataFrames: (365, 8) (365, 8) (366, 8) (365, 8) (365, 8)\n"
     ]
    }
   ],
   "source": [
    "for year in range(2018, 2024):\n",
    "    miss_count = locals()[f'df_{year}'].apply(lambda row: any(row == 'Miss '), axis=1).sum()\n",
    "    print(f\"Number of rows containing 'Miss' in df_{year} are/is: {miss_count}\")\n",
    "\n",
    "print('\\nShapes of DataFrames:',df_2018.shape, df_2019.shape, df_2020.shape, df_2021.shape, df_2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all weather dataframes into one DataFrame\n",
    "weather_df = pd.concat([df_2018, df_2019, df_2020, df_2021, df_2022, df_2023], ignore_index=True)\n",
    "weather_df.sort_values('Date', inplace=True)\n",
    "weather_df['Date'].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2018) + len(df_2019) + len(df_2020) + len(df_2021) + len(df_2022) + len(df_2023)  == len(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Maximum T</th>\n",
       "      <th>Minimum T</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  Maximum T  Minimum T  Precipitation  Snow       Date\n",
       "0     2018      1    1         30         12            0.0   0.0 2018-01-01\n",
       "1     2018      1    2         46         12            0.0   0.0 2018-01-02\n",
       "2     2018      1    3         50         20            0.0   0.0 2018-01-03\n",
       "3     2018      1    4         52         24            0.0   0.0 2018-01-04\n",
       "4     2018      1    5         62         25            0.0   0.0 2018-01-05\n",
       "...    ...    ...  ...        ...        ...            ...   ...        ...\n",
       "2155  2023     11   26         38         12            0.0   0.0 2023-11-26\n",
       "2156  2023     11   27         43         15            0.0   0.0 2023-11-27\n",
       "2157  2023     11   28         53         24            0.0   0.0 2023-11-28\n",
       "2158  2023     11   29         52         23            0.0   0.0 2023-11-29\n",
       "2159  2023     11   30         38         22            0.0   0.0 2023-11-30\n",
       "\n",
       "[2160 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with value equal to -998.0 are/is: 0\n"
     ]
    }
   ],
   "source": [
    "# In https://psl.noaa.gov/boulder/getdata.html tell us Missing values are indicated by -998.0.\n",
    "# So we count rows where any value in the selected columns is equal to -998\n",
    "count_missing_values = (weather_df[['Year', 'Month', 'Day', 'Maximum T', 'Minimum T', 'Precipitation', 'Snow']] == -998).any(axis=1).sum()\n",
    "\n",
    "print(f\"Number of rows with value equal to -998.0 are/is: {count_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year             0\n",
       "Month            0\n",
       "Day              0\n",
       "Maximum T        0\n",
       "Minimum T        0\n",
       "Precipitation    0\n",
       "Snow             0\n",
       "Date             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2160 entries, 0 to 2159\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Year           2160 non-null   int64         \n",
      " 1   Month          2160 non-null   int64         \n",
      " 2   Day            2160 non-null   int64         \n",
      " 3   Maximum T      2160 non-null   int64         \n",
      " 4   Minimum T      2160 non-null   int64         \n",
      " 5   Precipitation  2160 non-null   float64       \n",
      " 6   Snow           2160 non-null   float64       \n",
      " 7   Date           2160 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(5)\n",
      "memory usage: 151.9 KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Weather Data into the BOULDER Electric Vehicle Charging Station DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectId2</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>Zip_Postal_Code</th>\n",
       "      <th>Start_Date___Time</th>\n",
       "      <th>Start_Time_Zone</th>\n",
       "      <th>End_Date___Time</th>\n",
       "      <th>End_Time_Zone</th>\n",
       "      <th>Total_Duration__hh_mm_ss_</th>\n",
       "      <th>Charging_Time__hh_mm_ss_</th>\n",
       "      <th>Energy__kWh_</th>\n",
       "      <th>GHG_Savings__kg_</th>\n",
       "      <th>Gasoline_Savings__gallons_</th>\n",
       "      <th>Port_Type</th>\n",
       "      <th>ObjectID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / JUNCTION ST1</td>\n",
       "      <td>2280 Junction Pl</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80301</td>\n",
       "      <td>1/1/2018 17:49</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1/1/2018 19:52</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2:03:02</td>\n",
       "      <td>2:02:44</td>\n",
       "      <td>6.504</td>\n",
       "      <td>2.732</td>\n",
       "      <td>0.816</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BOULDER / JUNCTION ST1</td>\n",
       "      <td>2280 Junction Pl</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80301</td>\n",
       "      <td>1/2/2018 8:52</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1/2/2018 9:16</td>\n",
       "      <td>MDT</td>\n",
       "      <td>0:24:34</td>\n",
       "      <td>0:24:19</td>\n",
       "      <td>2.481</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.311</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BOULDER / JUNCTION ST1</td>\n",
       "      <td>2280 Junction Pl</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80301</td>\n",
       "      <td>1/2/2018 21:11</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1/3/2018 6:23</td>\n",
       "      <td>MDT</td>\n",
       "      <td>9:12:21</td>\n",
       "      <td>3:40:52</td>\n",
       "      <td>15.046</td>\n",
       "      <td>6.319</td>\n",
       "      <td>1.888</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BOULDER / ALPINE ST1</td>\n",
       "      <td>1275 Alpine Ave</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80304</td>\n",
       "      <td>1/3/2018 9:19</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1/3/2018 11:14</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1:54:51</td>\n",
       "      <td>1:54:29</td>\n",
       "      <td>6.947</td>\n",
       "      <td>2.918</td>\n",
       "      <td>0.872</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>900 Baseline Rd</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80302</td>\n",
       "      <td>1/3/2018 14:13</td>\n",
       "      <td>MDT</td>\n",
       "      <td>1/3/2018 14:30</td>\n",
       "      <td>MDT</td>\n",
       "      <td>0:16:58</td>\n",
       "      <td>0:16:44</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.226</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectId2            Station_Name           Address     City  \\\n",
       "0          1  BOULDER / JUNCTION ST1  2280 Junction Pl  Boulder   \n",
       "1          2  BOULDER / JUNCTION ST1  2280 Junction Pl  Boulder   \n",
       "2          3  BOULDER / JUNCTION ST1  2280 Junction Pl  Boulder   \n",
       "3          4    BOULDER / ALPINE ST1   1275 Alpine Ave  Boulder   \n",
       "4          5  BOULDER / BASELINE ST1   900 Baseline Rd  Boulder   \n",
       "\n",
       "  State_Province  Zip_Postal_Code Start_Date___Time Start_Time_Zone  \\\n",
       "0       Colorado            80301    1/1/2018 17:49             MDT   \n",
       "1       Colorado            80301     1/2/2018 8:52             MDT   \n",
       "2       Colorado            80301    1/2/2018 21:11             MDT   \n",
       "3       Colorado            80304     1/3/2018 9:19             MDT   \n",
       "4       Colorado            80302    1/3/2018 14:13             MDT   \n",
       "\n",
       "  End_Date___Time End_Time_Zone Total_Duration__hh_mm_ss_  \\\n",
       "0  1/1/2018 19:52           MDT                   2:03:02   \n",
       "1   1/2/2018 9:16           MDT                   0:24:34   \n",
       "2   1/3/2018 6:23           MDT                   9:12:21   \n",
       "3  1/3/2018 11:14           MDT                   1:54:51   \n",
       "4  1/3/2018 14:30           MDT                   0:16:58   \n",
       "\n",
       "  Charging_Time__hh_mm_ss_  Energy__kWh_  GHG_Savings__kg_  \\\n",
       "0                  2:02:44         6.504             2.732   \n",
       "1                  0:24:19         2.481             1.042   \n",
       "2                  3:40:52        15.046             6.319   \n",
       "3                  1:54:29         6.947             2.918   \n",
       "4                  0:16:44         1.800             0.756   \n",
       "\n",
       "   Gasoline_Savings__gallons_ Port_Type  ObjectID  \n",
       "0                       0.816   Level 2         0  \n",
       "1                       0.311   Level 2         1  \n",
       "2                       1.888   Level 2         2  \n",
       "3                       0.872   Level 2         3  \n",
       "4                       0.226   Level 2         4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ObjectId2', 'Station_Name', 'Address', 'City', 'State_Province',\n",
       "       'Zip_Postal_Code', 'Start_Date___Time', 'Start_Time_Zone',\n",
       "       'End_Date___Time', 'End_Time_Zone', 'Total_Duration__hh_mm_ss_',\n",
       "       'Charging_Time__hh_mm_ss_', 'Energy__kWh_', 'GHG_Savings__kg_',\n",
       "       'Gasoline_Savings__gallons_', 'Port_Type', 'ObjectID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Date___Time</th>\n",
       "      <th>End_Date___Time</th>\n",
       "      <th>Total_Duration__hh_mm_ss_</th>\n",
       "      <th>Charging_Time__hh_mm_ss_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2018 17:49</td>\n",
       "      <td>1/1/2018 19:52</td>\n",
       "      <td>2:03:02</td>\n",
       "      <td>2:02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/2018 8:52</td>\n",
       "      <td>1/2/2018 9:16</td>\n",
       "      <td>0:24:34</td>\n",
       "      <td>0:24:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2/2018 21:11</td>\n",
       "      <td>1/3/2018 6:23</td>\n",
       "      <td>9:12:21</td>\n",
       "      <td>3:40:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/3/2018 9:19</td>\n",
       "      <td>1/3/2018 11:14</td>\n",
       "      <td>1:54:51</td>\n",
       "      <td>1:54:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/3/2018 14:13</td>\n",
       "      <td>1/3/2018 14:30</td>\n",
       "      <td>0:16:58</td>\n",
       "      <td>0:16:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start_Date___Time End_Date___Time Total_Duration__hh_mm_ss_  \\\n",
       "0    1/1/2018 17:49  1/1/2018 19:52                   2:03:02   \n",
       "1     1/2/2018 8:52   1/2/2018 9:16                   0:24:34   \n",
       "2    1/2/2018 21:11   1/3/2018 6:23                   9:12:21   \n",
       "3     1/3/2018 9:19  1/3/2018 11:14                   1:54:51   \n",
       "4    1/3/2018 14:13  1/3/2018 14:30                   0:16:58   \n",
       "\n",
       "  Charging_Time__hh_mm_ss_  \n",
       "0                  2:02:44  \n",
       "1                  0:24:19  \n",
       "2                  3:40:52  \n",
       "3                  1:54:29  \n",
       "4                  0:16:44  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Start_Date___Time','End_Date___Time','Total_Duration__hh_mm_ss_','Charging_Time__hh_mm_ss_']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_columns_to_datetime(df, date_columns):\n",
    "    for column in date_columns:\n",
    "        df[column] = df[column].apply(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Must have as a seperator ':'\n",
    "def date_columns_to_timedelta(time_str):\n",
    "    try:\n",
    "        hours, minutes, seconds = map(int, time_str.split(':'))\n",
    "        return pd.Timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "    except ValueError:\n",
    "        return pd.NaT  # Handle invalid time format  \n",
    "    \n",
    "# Make the columns datetimes and timedelta\n",
    "df1 = df.copy()\n",
    "\n",
    "date_columns_to_dt= ['Start_Date___Time','End_Date___Time']\n",
    "df1 = date_columns_to_datetime(df1, date_columns_to_dt)\n",
    "\n",
    "date_columns_to_td = ['Total_Duration__hh_mm_ss_','Charging_Time__hh_mm_ss_']\n",
    "for column in date_columns_to_td:\n",
    "    df1[column] = df1[column].apply(date_columns_to_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Date___Time</th>\n",
       "      <th>End_Date___Time</th>\n",
       "      <th>Total_Duration__hh_mm_ss_</th>\n",
       "      <th>Charging_Time__hh_mm_ss_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 17:49:00</td>\n",
       "      <td>2018-01-01 19:52:00</td>\n",
       "      <td>0 days 02:03:02</td>\n",
       "      <td>0 days 02:02:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 08:52:00</td>\n",
       "      <td>2018-01-02 09:16:00</td>\n",
       "      <td>0 days 00:24:34</td>\n",
       "      <td>0 days 00:24:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02 21:11:00</td>\n",
       "      <td>2018-01-03 06:23:00</td>\n",
       "      <td>0 days 09:12:21</td>\n",
       "      <td>0 days 03:40:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-03 09:19:00</td>\n",
       "      <td>2018-01-03 11:14:00</td>\n",
       "      <td>0 days 01:54:51</td>\n",
       "      <td>0 days 01:54:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-03 14:13:00</td>\n",
       "      <td>2018-01-03 14:30:00</td>\n",
       "      <td>0 days 00:16:58</td>\n",
       "      <td>0 days 00:16:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start_Date___Time     End_Date___Time Total_Duration__hh_mm_ss_  \\\n",
       "0 2018-01-01 17:49:00 2018-01-01 19:52:00           0 days 02:03:02   \n",
       "1 2018-01-02 08:52:00 2018-01-02 09:16:00           0 days 00:24:34   \n",
       "2 2018-01-02 21:11:00 2018-01-03 06:23:00           0 days 09:12:21   \n",
       "3 2018-01-03 09:19:00 2018-01-03 11:14:00           0 days 01:54:51   \n",
       "4 2018-01-03 14:13:00 2018-01-03 14:30:00           0 days 00:16:58   \n",
       "\n",
       "  Charging_Time__hh_mm_ss_  \n",
       "0          0 days 02:02:44  \n",
       "1          0 days 00:24:19  \n",
       "2          0 days 03:40:52  \n",
       "3          0 days 01:54:29  \n",
       "4          0 days 00:16:44  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['Start_Date___Time','End_Date___Time','Total_Duration__hh_mm_ss_','Charging_Time__hh_mm_ss_']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "End_Date___Time    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()[df1.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a Date column to use it like a foreign key for the weather DataFrames\n",
    "df1[\"Date\"] = df1['Start_Date___Time'].dt.date.astype(\"datetime64\")\n",
    "\n",
    "# Sort increasing the dates per stations \n",
    "print(df1['Date'].is_monotonic_increasing)\n",
    "#print(df1.groupby('Station_Name')['Date'].apply(lambda x: x.is_monotonic_increasing).all())\n",
    "\n",
    "df1.sort_values(by='Date', inplace=True)\n",
    "print(df1['Date'].is_monotonic_increasing)\n",
    "#df1.sort_values(by=['Station_Name', 'Date'], inplace=True)\n",
    "#print(df1.groupby('Station_Name')['Date'].apply(lambda x: x.is_monotonic_increasing).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148136, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(148136, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the main Dataframe with the Weather Data\n",
    "print(df1.shape)\n",
    "df1 = df1.merge(weather_df, on='Date', how='left')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "End_Date___Time    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()[df1.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning / Preparation Based on paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the Dataset was considered: station ID and location, connection port, start and end times, connection\n",
    "durations, charging durations, kWh consumed, greenhouse gas reductions and gasoline\n",
    "savings, and unique driver identification.\n",
    "- The snow and precipitation was input in millimeters\n",
    "- Min and Max temperature in Fahrenheit (◦F)\n",
    "- Weekday is a Categorical variable Mon, Tue, Wed, Thu, Fri, Sat, and Sun\n",
    "- Month also is a Categorical variable Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, and Dec\n",
    "- All missing and negative data were removed from the dataset\n",
    "\n",
    "**We are apply this preprocessing rules in entire dataset the paper use 43,659 charging sessions (January 2018 to August 2022)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Measurements: \n",
    "- Temperatures are in degrees Fahrenheit (◦F).\n",
    "- Precipitation, snowfall and snow depth are in inches\n",
    "  \n",
    "**1 inche = 25.4 mm**      |   Source: https://www.unitconverters.net/length/inches-to-mm.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We drop the 0.109 % of the Dataset.\n"
     ]
    }
   ],
   "source": [
    "def data_transformation(df):\n",
    "\n",
    "    # Convert inches to millimeters\n",
    "    df['Snow'] = df['Snow'] * 25.4\n",
    "    df['Precipitation'] = df['Precipitation'] * 25.4\n",
    "\n",
    "    # Make the Month and Day to categorical variables \n",
    "    df['Weekday'] = df['Date'].dt.day_name()\n",
    "    df['Month'] = df['Date'].dt.month_name()\n",
    "\n",
    "    # Remove null (0) values in Engery_kwh_\n",
    "    df = df[df['Energy__kWh_'] > 0]\n",
    "\n",
    "    # Change datatype from float to integer\n",
    "    df[[\"Year\", \"Day\"]] = df[[\"Year\", \"Day\"]].astype(np.int64)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df2 = df1.copy()\n",
    "df2 = data_transformation(df1)\n",
    "print('We drop the',round((df1.shape[0] - df2.shape[0]) / df1.shape[0],3),'% of the Dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001     71\n",
       "0.008     56\n",
       "0.002     47\n",
       "0.014     43\n",
       "0.006     35\n",
       "          ..\n",
       "29.271     1\n",
       "14.800     1\n",
       "58.241     1\n",
       "17.243     1\n",
       "12.436     1\n",
       "Name: Energy__kWh_, Length: 23040, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Energy__kWh_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy__kWh_</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Minimum T</th>\n",
       "      <th>Maximum T</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.504</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.504</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.046</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.481</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.046</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148130</th>\n",
       "      <td>24.374</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148131</th>\n",
       "      <td>8.123</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148132</th>\n",
       "      <td>12.436</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148133</th>\n",
       "      <td>15.692</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148135</th>\n",
       "      <td>17.755</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>2023</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132023 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Energy__kWh_       Date  Day  Year   Weekday     Month  Minimum T  \\\n",
       "0              6.504 2018-01-01    1  2018    Monday   January         12   \n",
       "1              6.504 2018-01-01    1  2018    Monday   January         12   \n",
       "2             15.046 2018-01-02    2  2018   Tuesday   January         12   \n",
       "3              2.481 2018-01-02    2  2018   Tuesday   January         12   \n",
       "4             15.046 2018-01-02    2  2018   Tuesday   January         12   \n",
       "...              ...        ...  ...   ...       ...       ...        ...   \n",
       "148130        24.374 2023-11-30   30  2023  Thursday  November         22   \n",
       "148131         8.123 2023-11-30   30  2023  Thursday  November         22   \n",
       "148132        12.436 2023-11-30   30  2023  Thursday  November         22   \n",
       "148133        15.692 2023-11-30   30  2023  Thursday  November         22   \n",
       "148135        17.755 2023-11-30   30  2023  Thursday  November         22   \n",
       "\n",
       "        Maximum T  Snow  Precipitation  \n",
       "0              30   0.0            0.0  \n",
       "1              30   0.0            0.0  \n",
       "2              46   0.0            0.0  \n",
       "3              46   0.0            0.0  \n",
       "4              46   0.0            0.0  \n",
       "...           ...   ...            ...  \n",
       "148130         38   0.0            0.0  \n",
       "148131         38   0.0            0.0  \n",
       "148132         38   0.0            0.0  \n",
       "148133         38   0.0            0.0  \n",
       "148135         38   0.0            0.0  \n",
       "\n",
       "[132023 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[['Energy__kWh_','Date','Day','Year','Weekday','Month','Minimum T','Maximum T','Snow','Precipitation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Dataset into Daily, Weekly and Monthly aggregated datasets and keep the features based on paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before the filtering:\n",
      "Start and End Datetime: 2018-01-01 00:00:00 2022-08-31 00:00:00 \n",
      "Length: 41644 \n",
      "\n",
      "DataFrame after the filtering:\n",
      "Start and End Datetime: 2018-01-01 00:00:00 2022-07-31 00:00:00 \n",
      "Length: 39774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The paper approach duration (January 2018 to August 2022)\n",
    "print('DataFrame before the filtering:\\nStart and End Datetime:',df2.Date.min(), df2.Date.max(),'\\nLength:',len(df2),'\\n')\n",
    "df2 = df2[df2['Date'] < '2022-08-01']\n",
    "df2['Date'] = df2.loc[:, 'Date'].apply(pd.to_datetime)\n",
    "\n",
    "columns = ['Energy__kWh_','Date','Day','Year','Weekday','Month','Minimum T','Maximum T','Snow','Precipitation']\n",
    "df2.drop_duplicates(subset=columns, keep='first', inplace=True)\n",
    "print('DataFrame after the filtering:\\nStart and End Datetime:',df2.Date.min(), df2.Date.max(),'\\nLength:',len(df2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy__kWh_</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Minimum T</th>\n",
       "      <th>Maximum T</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.504</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Monday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.046</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.481</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>January</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.947</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.800</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Energy__kWh_       Date  Day  Year    Weekday    Month  Minimum T  \\\n",
       "0         6.504 2018-01-01    1  2018     Monday  January         12   \n",
       "2        15.046 2018-01-02    2  2018    Tuesday  January         12   \n",
       "3         2.481 2018-01-02    2  2018    Tuesday  January         12   \n",
       "6         6.947 2018-01-03    3  2018  Wednesday  January         20   \n",
       "7         1.800 2018-01-03    3  2018  Wednesday  January         20   \n",
       "\n",
       "   Maximum T  Snow  Precipitation  \n",
       "0         30   0.0            0.0  \n",
       "2         46   0.0            0.0  \n",
       "3         46   0.0            0.0  \n",
       "6         50   0.0            0.0  \n",
       "7         50   0.0            0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[['Energy__kWh_','Date','Day','Year','Weekday','Month','Minimum T','Maximum T','Snow','Precipitation']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Date'].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_Of_Records</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Daily</th>\n",
       "      <td>1668.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>725.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekly</th>\n",
       "      <td>239.0</td>\n",
       "      <td>144.751</td>\n",
       "      <td>4097.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1015.725</td>\n",
       "      <td>15489.792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Number_Of_Records       min        max\n",
       "Daily               1668.0     0.749    725.552\n",
       "Weekly               239.0   144.751   4097.781\n",
       "Monthly               55.0  1015.725  15489.792"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop_duplicates(inplace=True)\n",
    "\n",
    "# Daily dataset - Aggregated by sum\n",
    "columns_daily = ['Energy__kWh_', 'Weekday', 'Month', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation']\n",
    "daily_df = df2.groupby(['Date', 'Month', 'Weekday'], as_index=False).sum(numeric_only=True)[columns_daily]\n",
    "\n",
    "# Weekly dataset - Aggregated by sum\n",
    "columns_weekly = ['Energy__kWh_', 'Day', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation']\n",
    "weekly_df = df2.groupby(pd.Grouper(freq='W', key='Date')).sum(numeric_only=True)[columns_weekly]\n",
    "\n",
    "# Monthly dataset - Aggregated by sum\n",
    "columns_monthly = ['Energy__kWh_', 'Month', 'Minimum T', 'Maximum T', 'Snow', 'Precipitation']\n",
    "monthly_df = df2.groupby(['Month', 'Year', ], as_index=False).sum(numeric_only=True)[columns_monthly]\n",
    "\n",
    "\n",
    "# Evaluate the statistics Based On Paper\n",
    "\n",
    "# Daily analysis\n",
    "daily_stats = pd.DataFrame(daily_df['Energy__kWh_'].describe()[['count', 'min', 'max']])\n",
    "daily_stats.rename(index={'count': 'Number_Of_Records'}, inplace=True)\n",
    "\n",
    "# Weekly analysis\n",
    "weekly_stats = pd.DataFrame(weekly_df['Energy__kWh_'].describe()[['count', 'min', 'max']])\n",
    "weekly_stats.rename(index={'count': 'Number_Of_Records'}, inplace=True)\n",
    "\n",
    "# Monthly analysis\n",
    "monthly_stats = pd.DataFrame(monthly_df['Energy__kWh_'].describe()[['count', 'min', 'max']])\n",
    "monthly_stats.rename(index={'count': 'Number_Of_Records'}, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "stats_df = pd.concat([daily_stats, weekly_stats, monthly_stats], axis=1)\n",
    "stats_df.columns = ['Daily', 'Weekly', 'Monthly']\n",
    "stats_df.T # Transpose the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/Statistical_Summary.jpg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_df.to_csv('../Dataset/Boulder_Daily.csv')\n",
    "# weekly_df.to_csv('../Dataset/Boulder_Weekly.csv')\n",
    "# monthly_df.to_csv('../Dataset/Boulder_Monthly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
